{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU groq python-docx \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from groq import Groq\n",
    "from itertools import cycle\n",
    "import threading\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKeys = [\n",
    "    os.environ.get(\"GROQ_API_KEY_1\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_2\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_3\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_4\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_5\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_6\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_7\"),\n",
    "    os.environ.get(\"GROQ_API_KEY_8\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "groqClients = [Groq(api_key=key) for key in apiKeys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "repo_scan_report = os.path.join(output_dir, \"repo_scan_report.json\")\n",
    "with open(repo_scan_report, \"r\") as file:\n",
    "    repo_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_cycle = cycle(groqClients)\n",
    "\n",
    "\n",
    "def call_groq(prompt):\n",
    "    groq = next(groq_cycle)\n",
    "    chat_completion = groq.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(queue, file_list, microservices, file_descriptions, lock):\n",
    "    while not queue.empty():\n",
    "        file = queue.get()\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert software architect analyzing a monolithic codebase to plan its migration to a microservices architecture. \n",
    "\n",
    "        ### Task:\n",
    "        Determine whether the given file should be split into smaller, more modular files as part of a microservices-based system.\n",
    "        Make sure to give output in single valid JSON format only.\n",
    "\n",
    "        ### Given File:\n",
    "        - **Name**: {file[\"name\"]}\n",
    "        - **Path**: {file[\"path\"]}\n",
    "        - **Content**: {file[\"content\"][:2000]}  # Limiting content to prevent exceeding token limits\n",
    "\n",
    "        ### Project Context:\n",
    "        Here is a list of all the files in the repository to provide context:\n",
    "        {json.dumps(file_list)}\n",
    "\n",
    "        ### Instructions:\n",
    "        - **Analyze** the given file and decide whether it needs to be split.\n",
    "        - **If splitting is needed**, generate new file paths and names that describe their intended purpose.\n",
    "        - **If the file does NOT need to be split**, return the file in the same path.\n",
    "        - **Additionally**, provide a short description for each new file, explaining its functionality.\n",
    "        - **Ensure that the output strictly follows the JSON format below**.\n",
    "\n",
    "        ### Response Format:\n",
    "        Your response must be in **valid JSON format**, following this structure:\n",
    "        ```json\n",
    "        {{\n",
    "            \"microservice_mapping\": {{\n",
    "                \"{file[\"path\"]}\": [\"new_file_path_with_name.py\", \"new_file_path_with_name.py\"]\n",
    "            }},\n",
    "            \"file_descriptions\": {{\n",
    "                \"new_file_path_with_name.py\": \"Short description of its functionality\",\n",
    "                \"new_file_path_with_name.py\": \"Another short description\"\n",
    "            }}\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        ### Rules:\n",
    "        1. **Only split if necessary** : If the file is already modular, return its original path without modifications.\n",
    "        2. **Maintain file relationships** : If splitting, ensure logically related functions remain together.\n",
    "        3. **Use meaningful names** : New filenames should clearly reflect their role in the microservices architecture.\n",
    "        4. **Provide concise descriptions** : Explain the functionality of each new file in one sentence.\n",
    "        5. **No explanations or extra text** : Only return valid JSON.\n",
    "\n",
    "        ### Example Responses:\n",
    "\n",
    "        #### **Case 1: The file needs to be split**\n",
    "        ```json\n",
    "        {{\n",
    "            \"microservice_mapping\": {{\n",
    "                \"{file[\"path\"]}\": [\"services/auth/user_auth.py\", \"services/auth/token_handler.py\"]\n",
    "            }},\n",
    "            \"file_descriptions\": {{\n",
    "                \"services/auth/user_auth.py\": \"Handles user authentication and session management.\",\n",
    "                \"services/auth/token_handler.py\": \"Manages JWT token generation and validation.\"\n",
    "            }}\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        #### **Case 2: The file does NOT need to be split**\n",
    "        ```json\n",
    "        {{\n",
    "            \"microservice_mapping\": {{\n",
    "                \"{file[\"path\"]}\": [\"{file[\"path\"]}\"]\n",
    "            }},\n",
    "            \"file_descriptions\": {{\n",
    "                \"{file[\"path\"]}\": \"This file does not need splitting and remains unchanged.\"\n",
    "            }}\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        Now, analyze the given file and generate the response in the requested format.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            json_output = call_groq(prompt)\n",
    "\n",
    "            json_match = re.search(r\"\\{.*\\}\", json_output, re.DOTALL)\n",
    "            if not json_match:\n",
    "                raise ValueError(\"No valid JSON found in the response.\")\n",
    "\n",
    "            json_str = json_match.group(0)\n",
    "            response_data = json.loads(json_str)\n",
    "\n",
    "            with lock:\n",
    "                microservices.update(response_data.get(\"microservice_mapping\", {}))\n",
    "                file_descriptions.update(response_data.get(\"file_descriptions\", {}))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {file['name']}: {e}\")\n",
    "        finally:\n",
    "            queue.task_done()\n",
    "\n",
    "def determine_microservice_splits(repo_data, num_threads=5):\n",
    "    file_list = [file[\"name\"] for file in repo_data[\"files\"]]\n",
    "    microservices = {}\n",
    "    file_descriptions = {}\n",
    "\n",
    "    q = Queue()\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    for file in repo_data[\"files\"]:\n",
    "        q.put(file)\n",
    "\n",
    "    threads = []\n",
    "    for _ in range(num_threads):\n",
    "        t = threading.Thread(target=worker, args=(q, file_list, microservices, file_descriptions, lock))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    q.join()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    return microservices, file_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Determining microservice splits...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Determining microservice splits...\")\n",
    "microservices, file_descriptions = determine_microservice_splits(repo_data)\n",
    "\n",
    "microservices_path = os.path.join(output_dir, \"microservice_splits.json\")\n",
    "file_descriptions_path = os.path.join(output_dir, \"file_descriptions.json\")\n",
    "file_combined = os.path.join(output_dir, \"file_combined.json\")\n",
    "\n",
    "nested_output = {}\n",
    "for js_file, py_files in microservices.items():\n",
    "    nested_output[js_file] = {\n",
    "        py_file: file_descriptions[py_file] for py_file in py_files\n",
    "    }\n",
    "\n",
    "with open(microservices_path, \"w\") as outfile:\n",
    "    json.dump(microservices, outfile, indent=4)\n",
    "\n",
    "with open(file_descriptions_path, \"w\") as outfile:\n",
    "    json.dump(file_descriptions, outfile, indent=4)\n",
    "\n",
    "with open(file_combined, \"w\") as outfile:\n",
    "    json.dump(nested_output, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

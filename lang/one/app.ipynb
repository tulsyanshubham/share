{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools import Tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant designed to handle various tasks including:\n",
    "- Answering general knowledge questions.\n",
    "- Performing mathematical calculations.\n",
    "- Retrieving real-time information from the web.\n",
    "- Providing research-based answers from the vector database.\n",
    "- Handling natural language queries efficiently.\n",
    "\n",
    "Instructions:\n",
    "- Always keep the response concise and clear.\n",
    "- If the user asks for real-time information, prioritize the web search tool.\n",
    "- If the query relates to mathematical expressions, use the calculator tool.\n",
    "- If the user seeks in-depth or document-based information, use the RAG tool.\n",
    "- For everything else, generate a response using the LLM.\n",
    "\n",
    "Be accurate, helpful, and concise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning! How can I help you today?\n",
      "\n",
      "GroqAI is a cutting-edge AI company that has developed a new type of processor specifically designed for machine learning workloads. Our processor, called the GroqTensor, enables faster and more efficient training and inference of deep learning models.\n",
      "\n",
      "Is there anything specific you would like to know about GroqAI or our technology? I'm here to assist you with any questions you may have.\n"
     ]
    }
   ],
   "source": [
    "# Check if the API key is already set\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "# Initialize the ChatGroq LLM with the system prompt\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    # system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "# Function to get a response from the LLM\n",
    "def get_response(input_text):\n",
    "    response = llm.invoke(input_text)\n",
    "    return response.content\n",
    "\n",
    "# Creating the LLM Tool\n",
    "llm_tool = Tool(\n",
    "    name=\"GroqAI\",\n",
    "    description=\"A powerful AI model that can generate text based on the input text.\",\n",
    "    func=get_response,\n",
    ")\n",
    "\n",
    "# Test the LLM tool\n",
    "print(llm_tool.run(\"Hey GroqAI, Good Morning!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: Sure! Here's the SQL query to show all users who have placed orders in the last 30 days:\n",
      "```vbnet\n",
      "SELECT DISTINCT u.id, u.name, u.email, u.created_at\n",
      "FROM Users u\n",
      "JOIN Orders o ON u.id = o.user_id\n",
      "WHERE o.order_date >= CURDATE() - INTERVAL 30 DAY;\n",
      "```\n",
      "This query first joins the `Users` table with the `Orders` table on the `user_id` column. Then, it filters the results to only include orders that have an `order_date` within the last 30 days using the `WHERE` clause. Finally, it selects the `id`, `name`, `email`, and `created_at` columns from the `Users` table and uses the `DISTINCT` keyword to ensure that each user is only displayed once in the result set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table_schemas = \"\"\"\n",
    "Users(id, name, email, created_at)\n",
    "Products(id, name, price, created_at)\n",
    "Orders(id, order_date, total_amount, user_id)\n",
    "\"\"\"\n",
    "\n",
    "# Function to convert natural language to SQL query\n",
    "def nl_to_sql(text: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following natural language command into an SQL query.\n",
    "    Use the following table schemas:\n",
    "\n",
    "    {table_schemas}\n",
    "\n",
    "    Command: {text}\n",
    "\n",
    "    SQL Query:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate SQL query\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# Create the tool\n",
    "nl_to_sql_tool = Tool(\n",
    "    name=\"Natural Language to SQL\",\n",
    "    func=nl_to_sql,\n",
    "    description=\"Converts natural language commands into SQL queries based on provided table schemas.\"\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "response = nl_to_sql_tool.run(\"Show me all users who have placed orders in the last 30 days\")\n",
    "print(\"Generated SQL Query:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Bengaluru, currently, the weather remains in a fair state. The temperature is a moderately hot 24°C (75.2°F). The current temperature is a few degrees off the lowest anticipated temperature. Check out our current live radar and weather forecasts for Bangalore, Karnataka, IN to help plan your day. Want to know what the weather is now? Check out our current live radar and weather forecasts for Bangalore, Karnataka, IN to help plan your day ... Today's Weather - Bangalore, IND. March 6, 2025 6:37 PM HAL Bangalore City Arpt . 86 ... Current Bangalore weather condition is Mist with real-time temperature (29°C), humidity 33%, wind 7.2km/h, pressure (1018mb), UV (9.3), visibility (5km) in Karnataka. ... The monthly weather averages in Bangalore consist of 19 sunny days, 1 cloudy days, 11 rainy days, and 0 snowy days. Bangalore - Weather Conditions. India. Locations. Temp ... Today's Weather in Bengaluru: In Bengaluru today, the weather is expected to be Fair with a maximum temperature of 27°C and a minimum of 16°C. The temperature in Bangalore today in the early morning is 21 ° C. If you take into account factors such as wind, humidity and other weather conditions, the temperatures can feel like 21 ° C. The chance of rain in Bangalore in the morning is 0%, and the wind will blow at 5 km/h.\n"
     ]
    }
   ],
   "source": [
    "search_tool = DuckDuckGoSearchRun()\n",
    "# @tool\n",
    "def search(text: str) -> str:\n",
    "    # print(\"duck_search_tool\")\n",
    "    return search_tool.invoke(text)\n",
    "    \n",
    "duck_search_tool = Tool(\n",
    "     name=\"DuckDuckGo Search\",\n",
    "     func=search,\n",
    "     description=\"Search DuckDuckGo for real-time information.\"\n",
    ")\n",
    "result = duck_search_tool.run(\"What is the current temperature of bengaluru\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 7\n"
     ]
    }
   ],
   "source": [
    "def calculator(inputs: str):\n",
    "    try:\n",
    "        return str(eval(inputs))  # Simple arithmetic operation\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "calculator_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator,\n",
    "    description=\"Performs basic arithmetic calculations. Input should be a mathematical expression.\"\n",
    ")\n",
    "print(\"Sum:\", calculator_tool.run(\"2*3+1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'MiKTeX pdfTeX-1.40.15', 'creator': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'creationdate': '2017-08-29T10:25:37+08:00', 'trapped': '/False', 'moddate': '2018-02-14T10:44:46-05:00', 'application': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'ptex.fullbanner': 'This is MiKTeX-pdfTeX 2.9.5496 (1.40.15)', 'source': './data/temp.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='Research on Machine Learning Algorithms\\nand Feature Extraction for Time Series\\nLei Li∗, Yabin Wu∗, Yihang Ou ∗, Qi Li ∗, Yanquan Zhou∗ and Daoxin Chen †\\n∗School of Computer\\nBeijing University of Posts and Telecommunications, 10 Xitucheng Road, Beijing, China, 100876\\nEmail: leili@bupt.edu.cn\\n†CapInfo Company Limited, No.23Zhichun Road, Haidian District, Beijing, China, 100191\\nEmail: chendaoxin@capinfo.com.cn\\nAbstract—This paper aims to use various machine\\nlearning algorithms and explore the inﬂuence between\\ndifferent algorithms and multi-feature in the time series.\\nThe real consumption records constitute the time series as\\nthe research object. We extract consumption mark, fre-\\nquency and other features. Moreover, we utilize support\\nvector machine (SVM), long short-term memory (LSTM)\\nand other algorithms to predict the user’s consump-\\ntion behavior. Besides, we have also implemented multi-\\nfeature fusion and multi-algorithm fusion with LSTM\\nand SVM. Eventually, the experimental results show\\nthat LSTM algorithms is advantageous in prediction\\nwhen the data is sparse. In the other hand, the SVM\\nis beneﬁcial when the data is more abundant. What’s\\nmore, LSTM-SVM fusion model has advantages on the\\nextracting features of LSTM and on the classiﬁcation of\\nSVM. In most cases, LSTM-SVM is most outstanding in\\nprediction.\\nI. I NTRODUCTION\\nWith the rapid development of Internet and infor-\\nmation technology, massive data is emerging. There-\\nfore, data mining becomes one of the most important\\nresearch ﬁelds nowadays. Time series analysis is a\\nmethod to explore all the information contained in the\\ntime series, to observe, to estimate and to study the\\nstatistical regularity in the process of long-term change\\nin such a set of real data [1]. The combination of\\ntime series and data mining can explore the changing\\nlaws of phenomena and make predictive control of the\\nactions that have not happened.\\nAs early as 1927, the British statistician Yule put\\nforward the Autoregressive (AR) model [2] used to\\npredict the law of market changes. In 1931, Walker\\nestablished the Moving Average (MA) model. Later,\\nhe combined these two models to establish an Autore-\\ngressive Moving Average (ARMA) model [3]. Based\\non previous research, Box and Jenkins proposed the\\nautoregressive integrated moving average (ARIMA)\\nmodel which is of great signiﬁcance for modern time\\nseries analysis and prediction [4]. These models are\\nknown as time series predictive studies of classical\\nmethods.\\nWith the recent rapid development and extensive use\\nof machine learning and neural networks, their combi-\\nnation with time series data mining has become a hot\\nissue. Thissen et al. [5] use ARIMA, Support Vector\\nMachine(SVM) and the Recurrent Neural Networks\\n(RNN) model to predict on different time series data\\nsets and to compare the effects of the various models\\nunder different tasks. Tian et al. [6] and Fu et al. [7] use\\nLong Short-Term Memory (LSTM) neutral network to\\nachieve trafﬁc ﬂow forecast. Wang et al. [8] use LSTM\\nfor earthquake prediction. Junxiang et al. [9] use RNN\\nto construct a framework about space-time forecasting\\nfor the time series formed by air pollutants. Kim [10]\\nuses SVM to predict the ﬁnancial time series.\\nFrom above studies, there are few studies focus\\non the effect of time series feature engineering on\\nthe prediction effect of various algorithms. Thus we\\nplan to work on the inﬂuence of various features in\\ndifferent algorithms for the time series, including the\\nrepresentative SVM and LSTM algorithms. Through\\nmulti-feature integration, we analyze the effect of the\\nfeatures. In addition, we combine the two algorithms\\nof LSTM and SVM. Experimental results show that it\\ncan combine the memory advantage of LSTM and the\\nclassiﬁcation advantage of SVM, and obtain the best\\nprediction result.\\nII. S YSTEM DESIGN\\nA. System architecture\\nFigure 1 shows our system architecture.\\nRaw Data Data \\nPre-processing \\nExtract \\nFeature \\nMulti-feature \\nConsumption Mark \\nConsumption \\nFrequency \\nConsumption \\nAmount \\nModels \\nSVM \\nRNN \\nLSTM \\nSVM-LSTM \\nLSTM-SVM \\nResults \\nAnalysis \\nFig. 1. System architecture\\n978-1-5386-3531-5/17/$31.00 c⃝2017 IEEE'), Document(metadata={'producer': 'MiKTeX pdfTeX-1.40.15', 'creator': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'creationdate': '2017-08-29T10:25:37+08:00', 'trapped': '/False', 'moddate': '2018-02-14T10:44:46-05:00', 'application': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'ptex.fullbanner': 'This is MiKTeX-pdfTeX 2.9.5496 (1.40.15)', 'source': './data/temp.pdf', 'total_pages': 5, 'page': 1, 'page_label': '2'}, page_content='B. Raw data\\nOur raw data is collected from the real users’\\nconsumption records, containing 21340966 records of\\n538052 users. The consumption time span of the data\\nis from June 26, 2014 to November 10, 2016, a total\\nof 869 days. We randomly select 50000 users, and\\nextract their consumption records as the data set for\\nour experimentation.\\nC. Pre-processing\\nWe extract all records, implement data cleaning and\\nintegration, then saving the required features.\\nD. Feature extraction\\nWe divide 869 days’ data into 124 weeks which\\nmeans time series include 124 dimensions. Then we\\nextract the following features in this time series.\\nConsumption mark: It refers to whether the user\\nconsume within a week, if consumption occurs then\\nrecording as 1, otherwise, recording it as 0.\\nConsumption frequency: It is the count of each users\\nconsumption times per week.\\nConsumption amount: It is the number of one’s all\\nconsumption money within a week.\\nE. Multi-feature fusion\\nThe above features can reﬂect the user’s consump-\\ntion behavior from different angles. In order to support\\nmore accurate knowledge mining and prediction, it\\nis necessary to integrate a variety of features, and\\ncomplement each other. So we try to combine the\\nabove features in different ways in our experiments.\\nF . Model Algorithms\\nAs mentioned earlier, this paper focuses on machine\\nlearning and deep learning algorithms, hence the fol-\\nlowing three algorithms are chosen for research.\\n1) SVM: SVM is a supervised learning model\\nwhose essence is a binary-classiﬁcation model. Its\\nbasic model is deﬁned in the feature space on the\\nlargest linear classiﬁer [11].\\n2) RNN: Compared with the traditional neural net-\\nwork, RNN has added a cyclic structure, which can\\nkeep the persistent memory of information.\\n3) LSTM: LSTM is a variant of RNN. LSTM\\nachieves the purpose of maintaining the persistence of\\ninformation through the control of the ”gate” inside\\nthe neuron, and avoids the problem of long-term de-\\npendence in RNN.\\nIn our experiments, for all network structures, the\\nnumber of hidden units is 128.\\n4) Integration of SVM and LSTM: Cimino et al.\\n[12] propose a series of LSTM-SVM structures for\\nfeature extraction and classiﬁcation, and effective in\\nsubject classiﬁcation and irony detection. In this paper,\\nwe try to combine SVM with LSTM in series, using\\nthe results of SVM as the input to LSTM and the\\nresults of LSTM as the output, which is called SVM-\\nLSTM. Similarly, we exchange the position of SVM\\nand LSTM, then we form the LSTM-SVM.\\nG. Evaluation method\\nThe task of our experimental system is mainly to\\npredict whether the user will consume or not in the\\nnext time unit, hence, we will pay more attention to the\\nprecision of the forecast. According to the confusion\\nmatrix [13], the precision P is deﬁned as follows:\\nP = TP\\nTP + FP (1)\\nIn addition, in order to accurately describe the rich\\ndegree of the data, we deﬁne a data abundance index\\nK. Suppose that a user group contains N users, each\\nof which has consumption records for Ci (i = 1, 2, ...,\\nN) weeks in 124 weeks. This user group data has the\\nrich degree as follows:\\nK =\\n∑N\\ni=1 Ci\\n124 ∗ N (2)\\nIII. E XPERIMENTAL DESIGN AND RESULTS\\nA. Experimental design\\nDifferent users have different consumption habits,\\nhence, building a uniﬁed model for all users cannot\\nperform effectively for all users. In fact, this has been\\nconﬁrmed in our original experiments. Consequently,\\nconsidering the similarities among some user consump-\\ntion behaviors, we use K-means to cluster users and\\ndivide user groups, and then we build model for each\\nuser group to predict their consumptions.\\nK-means is a typical cluster algorithm based on\\ndistance. We use K-means to cluster 50,000 users into 3\\ndifferent clusters. The 3 clusters are as follows: Group0\\nhas 29228 users, Group1 has 17154 users and Group2\\nhas 3618 users. Their data rich degrees are as follows:\\nGroup0:10.95%, Group1:28.49%, Group2:46.59%.\\nWe implement experiment for each user group,\\nusing former 123 weeks data to predict whether user\\nconsume in the 124th week, if consumes then recording\\nas ’1’, if not, recording as ’0’. We divide the data\\ninto training set and testing set as 9:1. The number of\\nusers in every user group’s testing set and the number\\nof users in each cluster are shown in table I. We\\nmainly analyze the following 3 problems through our\\nexperiments: What is the effect of each algorithm on\\nthe prediction of time series when the data is sparse\\nand has low data richness? What is the effect of adding\\nthe fusion features on the prediction results of each\\nalgorithm? What is the effect of the fusion between\\nalgorithms and how well they predict?\\nTABLE I\\nTHE NUMBER OF USERS IN EACH CLUSTER\\nUser group Group0 Group1 Group2\\n0 1754 942 126\\n1 471 712 192\\ntotal 2228 1654 318'), Document(metadata={'producer': 'MiKTeX pdfTeX-1.40.15', 'creator': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'creationdate': '2017-08-29T10:25:37+08:00', 'trapped': '/False', 'moddate': '2018-02-14T10:44:46-05:00', 'application': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'ptex.fullbanner': 'This is MiKTeX-pdfTeX 2.9.5496 (1.40.15)', 'source': './data/temp.pdf', 'total_pages': 5, 'page': 2, 'page_label': '3'}, page_content='B. Experimental results and analysis\\n1) Experiment 1: Taking the consumption marks as\\nfeatures, we use SVM, LSTM and RNN respectively\\nto train a model and predict for each user group. The\\nprediction precisions are as follows:\\nTABLE II\\nEXPERIMENT 1 RESULTS\\ngroups Group0 Group1 Group2\\nSVM LSTM RNN SVM LSTM RNN SVM LSTM RNN\\n0 0.78 0.79 0.81 0.62 0.62 0.63 0.80 0.57 0.48\\n1 0.00 0.86 0.46 0.58 0.51 0.52 0.65 0.67 0.69\\ntotal 0.62 0.80 0.73 0.60 0.57 0.58 0.71 0.63 0.61\\nGroup0’s user data is sparse and very imbalanced.\\nWe obtain high precision in the 0 category with these\\nalgorithms, but SVM cannot predict the 1 category\\nwhich is less proportion. LSTM can predict the 1 cat-\\negory with higher precision, which shows that LSTM\\nhas prominent effect on the unbalanced time series.\\nRNN also can predict the 1 category, but RNN cannot\\nﬁlter memory information. Therefore, prediction ability\\nof RNN is not so good as that of LSTM.\\nThe data richness of Group1 and Group2 are in-\\ncreased, therefore, these algorithms can predict both\\nof two types’ users. From the result, by increasing the\\nrichness of the data can improve performance, espe-\\ncially in type which low proportion. Besides, RNN’s\\nadvantageous beneﬁt from the data’s richness, so it’s\\nprecision is slightly better than LSTM. From another\\nangle, the Group2’s data is rich than the Group1 so\\nthe prediction of Group2 is improved. However, we\\nsee that the data richness exceed certain degree will\\nresult in RNN slightly inferior to LSTM. The reason\\nof this is that LSTM use the ’gate’ to ﬁlter data\\nwhich is help for remember the features, and eliminate\\nredundancy. Experiment 1 proves the advantage of\\nLSTM in memorizing long time series, when the data\\nis sparse, unbalanced sequence. And RNN is not as\\ngood as LSTM due to long-term dependence. Besides,\\nwhen data is abundant, SVM is more effective than\\nLSTM and RNN. Then we try adding new features,\\nand examine the effect of multi-feature fusion on each\\nalgorithm.\\n2) Experiment 2: We add the frequency features,\\nusing both of the consumption frequency and the con-\\nsumption mark as the features in this experiment. The\\nprediction results of each user group are as follows:\\nTABLE III\\nEXPERIMENT 2 RESULTS\\ngroups Group0 Group1 Group2\\nSVM LSTM RNN SVM LSTM RNN SVM LSTM RNN\\n0 0.79 0.79 0.80 0.61 0.62 0.57 0.71 0.57 0.00\\n1 0.67 0.86 0.60 0.59 0.51 0.65 0.64 0.67 0.60\\ntotal 0.76 0.80 0.76 0.60 0.57 0.60 0.67 0.63 0.36\\nAfter adding the frequency features, the effective\\nfeatures is further enriched. In Group0’s results, SVM\\ncan predict the class 1 and achieve 67% precision.\\nAdding features can improve SVM’s prediction on the\\ndata which is sparse and the class with less proportion\\nsigniﬁcantly. LSTM’s prediction is better than SVM\\nand RNN. For Group1, it can predict both classes, and\\nmaintain a stable forecast results. But the predictions\\nof LSTM have declined. The features added may have\\nan impact on LSTM’s memory ability, and there is a\\ncertain amount of useless noise. RNN cannot ﬁlter the\\ninformation, the noise doesn’t have a great impact, and\\nthe prediction results is better than that of LSTM. SVM\\nmaintains a high prediction precision while the data\\nis abundant. SVM in Group2 is same as in Group1,\\nit shows a prediction advantage when the data is\\nabundant, and achieves the highest prediction precision\\nin the three algorithms. LSTM’s precision is slightly\\nlower than SVM. In other words, when the data is more\\nabundant, LSTM’s prediction results can be poorer\\nthan that of SVM. RNN’s prediction result is abnormal,\\nthe prediction precision of class 0 is 0, which may\\nbe caused by overﬁtting. In our experiment, the neural\\nnetwork has 128 hidden units, which may be too many\\nfor the data. Hence, we try to reduce the number of\\nhidden units to 64 and 32. Each precision of 64-RNN\\nis: Class0:0.55, Class1:0.69 and total:0.64. And each\\nprecision of 32-RNN is: Class0:0.55, Class1:0.66 and\\ntotal:0.62.\\nAs we can see that RNN with 128 hidden units in\\nthe Group2 has the problem of overﬁtting. After adding\\nthe frequency features, the data richness increases to a\\ncertain extent, which has a negative impact on RNN.\\nIt appears overﬁtting faster than LSTM. In the same\\ndata size, LSTM can avoid the problem of overﬁtting\\nvery well through its own selective memory.\\nComparing the results of experiment 1 and exper-\\niment 2, we can see that the prediction precision of\\nLSTM on the three user groups does not change,\\nand adding the frequency features has little effect\\non LSTM. Adding features and enriching the valid\\ndata can improve SVM’s predictions on sparse and\\nunbalanced time series. But when the data is too rich,\\nexcessive noise can adversely affect the prediction\\nresults of SVM. When the data richness is low, adding\\nfeatures can also improve RNN’s result, but when the\\ndata is abundant, it is possible to make RNN appear\\noverﬁtting if we continue to add features.\\n3) Experiment 3: On the basis of experiment 2, we\\ncontinue to add the consumption amount as a feature,\\nand implement experiments for each user group with\\nconsumption amount, consumption frequency and con-\\nsumption mark as features. The prediction results for\\neach user group are as follows:\\nTABLE IV\\nTHE NUMBER OF USERS IN EACH CLUSTER\\ngroups Group0 Group1 Group2\\nSVM LSTM RNN SVM LSTM RNN SVM LSTM RNN\\n0 0.80 0.80 0.80 0.57 0.62 0.63 0.00 0.56 0.50\\n1 0.92 0.79 0.63 0.00 0.52 0.50 0.60 0.68 0.65\\ntotal 0.82 0.79 0.76 0.32 0.57 0.58 0.36 0.63 0.59'), Document(metadata={'producer': 'MiKTeX pdfTeX-1.40.15', 'creator': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'creationdate': '2017-08-29T10:25:37+08:00', 'trapped': '/False', 'moddate': '2018-02-14T10:44:46-05:00', 'application': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'ptex.fullbanner': 'This is MiKTeX-pdfTeX 2.9.5496 (1.40.15)', 'source': './data/temp.pdf', 'total_pages': 5, 'page': 3, 'page_label': '4'}, page_content='After adding consumption amount, features are in-\\ncreased and the data for training and testing is further\\nenriched. The three algorithms all can predict well on\\nGroup0, and SVM still maintains its advantages when\\nthe data is abundant. Likewise, LSTM is superior to\\nRNN in terms of long-term memory. SVM’s precision\\non Group1 has dropped signiﬁcantly, it cannot predict\\nthe less proportion class 1. According to the mutations\\nof RNN in experiment 2, we have a reason to think\\nthat SVM has been overﬁtted to cause the exception.\\nBoth LSTM and RNN can predict the consumption\\nbehaviors, and similarly as in the experiment 2, RNN’s\\nprecision is slightly higher than that of LSTM. SVM\\nalso appears abnormal situation on Group2 as same\\nas on Group1. The precision of LSTM is higher than\\nRNN on Group2. LSTM has advantages over long\\ntime series, and its ﬁltering memory capabilities for\\nabundant time series play an effective role.\\nComparing the results of the above three experi-\\nments, we can see that LSTM’s prediction precision\\ndecreases by 0.01 only in Group0, while remains stable\\nfor all the others, which further proves that adding fea-\\ntures has little effect on LSTM. As mentioned before,\\nthe three features used in the experiments have some\\nredundancy. For instance, if a user has consumption\\nmark of 1, then he certainly has consumption frequency\\nand consumption amount features. There are no feature\\ndata when users don’t consume. This redundancy may\\nbe the reason why multi-features cannot work for\\nLSTM. In experiment 3, it can be seen that SVM’s\\nprediction effect can be improved after adding some\\ndetailed features. However, when features are added to\\na certain extent, the redundancy will adversely affect\\nSVM, which will cause SVM overﬁtted. RNN overﬁts\\nin experiment 2, but in experiment 3, after adding\\nconsumption amount features, it doesn’t overﬁt. Taking\\ninto account that the absolute range of consumption\\namount is large, we normalize the amount, scale it to\\nthe range of [0, 1]. Experiment is implemented for\\nGroup2 again in order to verify its impact, and the\\nresults are: Class0:0.40, Class1:0.00 and Class:0.16.\\nAfter normalization, we can see that RNN has been\\noverﬁtted more seriously, and its prediction is further\\ndeteriorated. Therefore, we believe that the absolute\\nrange of the consumption amount is much larger com-\\npared with that of consumption mark and frequency,\\nwhich has an inﬂuence on RNN’s ﬁtting, making RNN\\ndoes not appear overﬁtting in experiment 3.\\nIn conclusion, we can see that the addition of\\nfeatures can effectively improve the performance on\\nsparse time series and the imbalanced category, espe-\\ncially for the performance of SVM. However, when\\nthe data is abundant to a certain extent, the redundant\\nfeatures will adversely affect the prediction of SVM\\nand RNN, their prediction precisions can be reduced,\\nand SVM and RNN will be overﬁtted. The added fea-\\ntures have little effect on LSTM’s prediction, therefore,\\nthrough the effective information ﬁltering, LSTM can\\nalso avoid the problem of overﬁtting.\\n4) Experiment 4: In the above experiments, we only\\nuse single algorithm to predict consumptions. We can\\nsee that each algorithm has its own advantages and\\ndisadvantages. Then we consider to fuse LSTM and\\nSVM, and inspect whether it can achieve the purpose\\nof learning from each other. We consider using LSTM\\nto extract the feature of the time series then use its\\nclassiﬁcation probability as the new features input into\\nSVM to predict. We refer to this fusion algorithm as\\nLSTM-SVM. Similarly,we exchange the LSTM and\\nSVM in LSTM-SVM then refer as SVM-LSTM. We\\nuse these two fusion algorithms to re-implement the\\nexperiments 1 to 3, and the results are as follows:\\nTABLE V\\nEXPERIMENT 1 RESULTS OF FUSION ALGORITHMS\\ngroups Group0 Group1 Group2\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\n0 0.79 0.81 0.59 0.63 0.82 0.71\\n1 0.89 0.43 0.56 0.55 0.63 0.65\\ntotal 0.81 0.73 0.58 0.60 0.71 0.67\\nAs we can see, both fusion algorithms can predict\\nboth categories. For Group0’s average prediction pre-\\ncision, we have LSTM-SVM>LSTM>RNN=SVM-\\nLSTM>SVM. Since LSTM can play its own memory\\nability when extracting features, and SVM can also\\nplay its own advantages on classiﬁcation, hence the\\nLSTM-SVM can achieve the best predictive results.\\nAs to SVM-LSTM, it acquired a part of the memory\\ncapability of LSTM. Thus it can predict the class 1,\\nand greatly improve SVM’s predictions on the less\\nproportion categories.\\nFor Group1’s average prediction precision, we have\\nSVM=SVM-LSTM>LSTM-SVM>RNN>LSTM.\\nSVM maintains the advantages when data is abundant.\\nFor Group2’s average prediction precision, we have\\nLSTM-SVM=SVM>SVM-LSTM>LSTM>RNN. At\\nthis time both SVM and LSTM-SVM have the same\\nprediction precision. Through the integration with\\nSVM, LSTM can also have SVM’s classiﬁcation\\nadvantages on the abundant data.\\nIn general, for the sparse data, LSTM-SVM fusion\\nmethod enhances the forecast signiﬁcantly, while for\\nthe abundant data, SVM has a better classiﬁcation\\nadvantages.\\nTABLE VI\\nEXPERIMENT 2 RESULTS OF FUSION ALGORITHMS\\ngroups Group0 Group1 Group2\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\n0 0.79 0.80 0.59 0.63 0.71 0.51\\n1 0.83 0.62 0.61 0.54 0.63 0.65\\ntotal 0.80 0.76 0.60 0.59 0.66 0.59'), Document(metadata={'producer': 'MiKTeX pdfTeX-1.40.15', 'creator': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'creationdate': '2017-08-29T10:25:37+08:00', 'trapped': '/False', 'moddate': '2018-02-14T10:44:46-05:00', 'application': \"'Certified by IEEE PDFeXpress at 08/28/2017 7:33:25 PM'\", 'ptex.fullbanner': 'This is MiKTeX-pdfTeX 2.9.5496 (1.40.15)', 'source': './data/temp.pdf', 'total_pages': 5, 'page': 4, 'page_label': '5'}, page_content='For Group0’s average prediction precision, we\\nhave LSTM-SVM=LSTM>SVM=SVM-LSTM=RNN.\\nLSTM-SVM still maintains the LSTM’s memory\\nand SVM’s classiﬁcation advantages, thus getting\\nthe highest prediction precision. For Group1’s\\naverage prediction precision, we have LSTM-\\nSVM=SVM=RNN>SVM-LSTM>LSTM. For\\nGroup2s average prediction precision, we have\\nSVM>LSTM-SVM>LSTM>SVM-LSTM>RNN.\\nIt can be seen that after the data becomes more\\nabundant, SVM still has a good prediction results,\\nLSTM-SVM in Group1 is as same as SVM, and in\\nGroup2 its precision is only 0.01% lower than that of\\nSVM.\\nTABLE VII\\nEXPERIMENT 3 RESULTS OF FUSION ALGORITHMS\\ngroups Group0 Group1 Group2\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\nLSTM-\\nSVM\\nSVM-\\nLSTM\\n0 0.79 0.80 0.59 0.00 0.77 0.40\\n1 0.83 0.85 0.59 0.43 0.63 0.00\\ntotal 0.80 0.81 0.59 0.19 0.69 0.16\\nFor Group0’s average prediction precision, we have\\nSVM>SVM-LSTM>LSTM-SVM>LSTM>RNN.\\nSVM still has its advantages with the highest\\nprecision when adding features and the effective\\ndata increased. In Group1, SVM has been overﬁtted,\\nwhich is the same as SVM-LSTM. The difference\\nis that SVM is unable to predict the less proportion\\ncategory, while SVM-LSTM is unable to predict\\nthe larger proportion category. This may be due to\\nafter LSTM ﬁltering the information, the remain\\nmemory information is different from SVM. For\\nGroup1’s average prediction precision, we have\\nLSTM-SVM>RNN>LSTM>SVM>SVM-LSTM.\\nLSTM-SVM effectively avoids overﬁtting. In Group2,\\nSVM and SVM-LSTM are overﬁtted as same as in\\nGroup1. For Group2’s average prediction precision,\\nwe have LSTM-SVM>LSTM>RNN>SVM>SVM-\\nLSTM. LSTM-SVM still has the highest precision.\\nIn the above three re-implemented experiments,\\nthere are 9 prediction results for the three user groups.\\nLSTM-SVM has the highest precision of 6 results\\nand SVM has the highest precision of 5 ones, and\\nthey have the same precision twice. We can see that\\nboth LSTM-SVM and SVM algorithms have the best\\nforecast results for most cases. SVM has very good\\npredictions when the data is abundant, but it is often\\nnot predictable for sparse time series, and SVM will\\nappear overﬁtting problem when the data is abundant\\nin some case. Overall, LSTM-SVM has signiﬁcant\\nadvantages over other algorithms with sparse data and\\nunbalanced time series. Moreover, after the data is\\nabundant, it can also effectively predict the results.\\nThere are no obvious shortcomings in LSTM-SVM,\\nand it can effectively avoid overﬁtting problems.\\nIV. C ONCLUSION\\nIn this paper, we use real user consumption records\\nto construct time series, and exact variety features to\\ncombine with machine learning algorithms to achieve\\nthe consumption prediction. We consider the impact\\nof different features on various algorithms and then\\nachieve multi-feature fusion and algorithm fusion to\\ncomplement the weakness of each single feature and\\nalgorithm. This study provides the basis for further\\nstudy. At the same time, it necessary to consider the\\ntime series various characteristics and application of\\npredictive model in the future.\\nACKNOWLEDGMENT\\nThis work was supported by the National Social\\nScience Foundation of China under Grant 16ZDA055;\\nNational Natural Science Foundation of China un-\\nder Grant 91546121, 71231002 and 61202247; EU\\nFP7 IRSES MobileCloud Project 612212; the 111\\nProject of China under Grant B08004; Engineering\\nResearch Center of Information Networks, Ministry of\\nEducation; the project of Beijing Institute of Science\\nand Technology Information; the project of CapInfo\\nCompany Limited.\\nREFERENCES\\n[1] L. Qi, Time Series Analysis Simple Course. Tsinghua Univer-\\nsity Press, 1999.\\n[2] Y . Wang and L. Wang, Application Time Series Analysis.\\nChina Renmin University Press, 2005.\\n[3] X. Xu, “Research and application on time series prediction\\nbased on data mining method.” Ph.D. dissertation, China\\nUniversity of Geosciences for Master Degree(Beijing), 2011.\\n[4] T. Le, Y . Cai, X. Ma, and L. Wang, “Development and applica-\\ntion of time series forecasting,”Ordnance Industry Automation,\\nno. 2, pp. 63–68, 2015.\\n[5] U. Thissen, R. Van Brakel, A. De Weijer, W. Melssen, and\\nL. Buydens, “Using support vector machines for time series\\nprediction,”Chemometrics and intelligent laboratory systems,\\nvol. 69, no. 1, pp. 35–49, 2003.\\n[6] Y . Tian and L. Pan, “Predicting short-term trafﬁc ﬂow by\\nlong short-term memory recurrent neural network,” in Smart\\nCity/SocialCom/SustainCom (SmartCity), 2015 IEEE Interna-\\ntional Conference on. IEEE, 2015, pp. 153–158.\\n[7] R. Fu, Z. Zhang, and L. Li, “Using lstm and gru neural network\\nmethods for trafﬁc ﬂow prediction,” in Chinese Association\\nof Automation (YAC), Youth Academic Annual Conference of.\\nIEEE, 2016, pp. 324–328.\\n[8] Q. Wang, Y . Guo, L. Yu, and P. Li, “Earthquake prediction\\nbased on spatio-temporal data mining: An lstm network ap-\\nproach,”IEEE Transactions on Emerging Topics in Computing,\\n2017.\\n[9] J. Fan, Q. Li, Y . Zhu, j. Hou, and y. Feng, “A spatiotemporal\\nprediction framework for air pollution based on deep rnn,”\\nScience of Surveying and Mapping, pp. 1–16, 2017(07).\\n[10] K.-j. Kim, “Financial time series forecasting using support\\nvector machines,” Neurocomputing, vol. 55, no. 1, pp. 307–\\n319, 2003.\\n[11] H. Li, Statistical Learning Method. Tsinghua University Press,\\n2012.\\n[12] A. Cimino and F. Dell’Orletta, “Tandem lstm-svm approach\\nfor sentiment analysis.” in CLiC-it/EVALITA, 2016.\\n[13] Z. Zhou, Machine Learning. Tsinghua University Press, 2015.')]\n",
      "Length of document is: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_document(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_document('./data/temp.pdf')\n",
    "print(documents)\n",
    "print(\"Length of document is:\",len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks is: 28\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of chunks is:\",len(texts))\n",
    "# for i, text in enumerate(texts):\n",
    "#     print(\"chunk\",i)\n",
    "#     print(text.page_content)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of text is: 28\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "for text in texts:\n",
    "    vector = embeddings.embed_query(text.page_content)\n",
    "    # print(vector, text.page_content)\n",
    "print(\"Lenght of text is:\",len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"psycopg[binary]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"psycopg-binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain_postgres psycopg[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU \"psycopg[c]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://postgres:postgres@localhost:5431/vectordb\"  # Uses psycopg3!\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def store_into_vectordb(splitted_texts):\n",
    "    documents = []\n",
    "    ids = []\n",
    "    for i, text in enumerate(texts):\n",
    "        ids.append(i)\n",
    "        documents.append(Document(page_content=text.page_content))\n",
    "    vector_store.add_documents(documents=documents, ids=ids)\n",
    "\n",
    "store_into_vectordb(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs is: 977\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(query=\"What are the leave policy\",k=1)\n",
    "docs = \"\"\n",
    "for doc in results:\n",
    "    docs+=f\"{doc.page_content} [{doc.metadata}]\"\n",
    "\n",
    "print(\"Length of docs is:\",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_tool_func(text: str) -> str:\n",
    "    results = vector_store.similarity_search(query=text,k=1)\n",
    "    docs = \"\"\n",
    "    for doc in results:\n",
    "        docs+=f\"{doc.page_content} [{doc.metadata}]\"\n",
    "    return docs\n",
    "    \n",
    "rag_tool = Tool(\n",
    "     name=\"Research on Machine Learning Algorithms and Feature Extraction for Time Series\",\n",
    "     func=rag_tool_func,\n",
    "     description=\"Research on Machine Learning Algorithms and Feature Extraction for Time Series\",\n",
    ")\n",
    "result = rag_tool.run(\"What are the leave policy\")\n",
    "# print(result)rag_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(name=\"GroqAI\", func=llm_tool.run, description=\"A powerful AI model that can generate text based on the input text.\"),\n",
    "    Tool(name=\"Web Search\", func=duck_search_tool.invoke, description=\"Search the web for information.\"),\n",
    "    Tool(name=\"Calculator\", func=calculator_tool.run, description=\"Perform calculations.\"),\n",
    "    Tool(name=\"Machine Learning Algorithms and Feature Extraction for Time Series\", func=rag_tool.run, description=\"Research on Machine Learning Algorithms and Feature Extraction for Time Series.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "\n",
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state):\n",
    "    query = state[\"input\"].lower()\n",
    "    if any(x in query for x in [\"calculate\", \"+\", \"-\", \"*\", \"/\"]):\n",
    "        return \"calculator\"\n",
    "    elif any(x in query for x in [\"Time Series\", \"Machine Learning\", \"Feature Extraction\"]):\n",
    "        return \"rag\"\n",
    "    elif any(x in query for x in [\"search\", \"web\", \"information\"]):\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        return \"groq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26004271910>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"calculator\", lambda state: {\"output\": calculator_tool.run(state[\"input\"])})\n",
    "graph.add_node(\"web_search\", lambda state: {\"output\": duck_search_tool.run(state[\"input\"])})\n",
    "graph.add_node(\"rag\", lambda state: {\"output\": rag_tool.run(state[\"input\"])})\n",
    "graph.add_node(\"groq\", lambda state: {\"output\": llm_tool.run(state[\"input\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26004271910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_conditional_edges(\n",
    "    START,\n",
    "    route_query,\n",
    "    {\n",
    "        \"calculator\": \"calculator\",\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"rag\": \"rag\",\n",
    "        \"groq\": \"groq\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"calculator\", END)\n",
    "graph.add_edge(\"web_search\", END)\n",
    "graph.add_edge(\"rag\", END)\n",
    "graph.add_edge(\"groq\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_graph=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAADqCAIAAADS9ID4AAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdYU1cfB/CTAQkhEJbsvUS2gCBDhaJYVLTUUfe2VlTUOqq1b22tVat1o6g4UCtqcaGiFaVWAS3IBkUQEBFCQFYgEzLeP26bWgREm3Ayzufp0yf7fr1Jfpyce+45OLFYDBAEQRDFh4cdAEEQBJEOVNARBEGUBCroCIIgSgIVdARBECWBCjqCIIiSQAUdQRBESRBhB0BUDo8jbKrr4LQJOO1CkRB0dohgJ3o3kgZeTR1P0SZQtAiGFmTYcRCke6igI/2Ezewsy2O9KGKzmAIqjUjRJlK0CFq6RKAIJ0KIhOK6Ki6nTaiuga9+xrFx1bR107R1pcLOhSD/gkMnFiGyJhSIH15vbGZ06JuQbNw0zew0YCf6T3hs4Ytidm0Fh17JC4gwsPdAZR2RF6igI7L15BHz/qXXAREGniN0YGeRMmZj58PrjYJOcdgsI5IGAXYcBEEFHZGlexcaKNoEv3B92EFk6HUN78pB+tiFJor+ywNRAqigI7Ly2ymGuaOGqz8NdpD+cPlAzYhJA/RNSLCDICoNFXREJi7H1Dj5aDsP1YYdpP9cOlAzOFjH1g11qSPQoHHoiPTdv/Ta3oOqUtUcADBxuXn61UZmUyfsIIjqQgUdkbJnj9tIGnj3Ycp2CLQvpq+3/P1CA+wUiOpCBR2RsvsXX3uF6sJOAQdRDW9ur/HnzSbYQRAVhQo6Ik2PU5o9Ruiok1T3czUkTK/gfmsHXwFOf0WUj+p+8RCpEwpEteXcoWOUeZBiX4yYPCDvXgvsFIgqQgUdkZrKIjZZE51fAywcKU8etsFOgagiVNARqaksZtu6avbzRr/66qvr169/wBNHjhxJp9NlkAhoahOpOsT6ap4sXhxBeoEKOiI1zMZOW/f+LuglJSUf8CwGg9Ha2iqDOH8Z6KP1qpQju9dHkG6hgo5IB7tNwGoRENVk9Ym6evXqlClTAgMDQ0ND165dW19fDwDw8fGh0+nff/99cHAwAEAoFB4+fPiTTz4JCAgIDw/fvn07l8vFnj5y5MiEhITo6Gh/f/+0tLRx48YBAMaPH7969WpZpNXUJr6u5cvilRGkF6igI9LBaRNStGXVgZ6Xl7dly5Zp06ZduHBh3759ra2t69evBwDcvHkTALB27dqkpCQAQEJCQnx8fFRU1Pnz5zdt2nT//v2DBw9ir0AkEi9fvmxvb3/kyJEhQ4Zs27YNAPDLL79s3rxZFoEp2gROm1AWr4wgvUDzoSPSwWkXULRk9XGqqKggkUgRERFEItHc3Hz79u11dXUAABqNBgCgUCjYhfDwcH9/f3t7ewCApaVlWFhYRkYG9go4HI5MJkdHR2NXNTU1AQDa2trYBanTpBHZTIEsXhlBeoEKOiIdIiEgUWT1g8/HxweHwy1cuHDChAl+fn6mpqb6+t0MjtTR0UlOTt6yZUtDQ4NAIOBwOBQKRXKvu7u7jOK9jUDAqZHRz1+kv6HPHCIdFC0Cs1FW05hYW1ufPHnS3Nz8wIED48ePnzt3bnFx8dsP27lz57Fjx6ZMmRIXF5eQkBAZGfnmvVRq/02bxWIKiERcv20OQTCooCPSIeteYwcHhy1btty5c+fIkSMEAmHlypUdHR1vPkAoFCYlJc2ZM2fMmDFmZmYGBgYsFkt2eXrHaRNQtNHPX6S/oYKOSAeVRtTWl1UJKy4uLiwsBAAQCARvb+8lS5a0trY2Nf01ZQo2BbRIJBIKhVhnOgCAzWY/ePCg99mhZTd3NJ8jHGCO5kZH+hsq6Ih04PA4dRL+xRO2LF784cOHX375ZWpqak1NTWlp6fnz501MTIyNjUkkEolEys3NLS0txeFwAwcOvHHjRk1NzfPnz1euXBkYGNjW1lZVVSUQdD0+qa2tDQBIT0+vrKyUReDSHJaJDVkWr4wgvUC/ChGpsXHTfFHEtnGR/riR+fPnd3Z27t279/Xr11Qq1cPDY//+/TgcDgAwd+7cU6dOpaWlXb169dtvv928efOUKVNMTU2XLFni6upaUFAwe/bs8+fPd3nBQYMGBQQE7Nmzx9PT8/Dhw9JN28kXMV7yLBwpfXgsgkgTWrEIkRp2uyA1oWH8YlPYQSCrLGTRK7lBnwyAHQRROajLBZEaTS0iTV+tMF2Gp9QrhIzrTa6BKrGSKiJvUJcLIk0BEfrHv33hHtT9ckUCgWDkyJHd3tXR0aGurt7tXTY2NidPnpRqzH/Ex8fHx8d3exeVSu1pnIyrq2tMTEy3dz35k2lmp6EzoPt/C4LIFOpyQaSms7NTTU0t914LgYjz6GEJuvb29m5v5/P56urqWLd4F3g8Xkbnc2Lb7TL8UQL753R7F4FAePOUpTddO1I7coYRhUosLy/X1dXt9gQoBJERVNCRD9fR0cHn87W0tH7++efr169fuHDB2NgYAHDtCN1jOM1qUH/PvAhd0uHawcG6lk4UAMCVK1diY2O//vrr4ODgjIwMPT29QYMGwQ6IKDnUh468HwaDwWAwAAC7du0aMWIENqfKqFGjkpOTsWoOABi/2PT3Cw3M1923fJXV3YR6y4EUrJoDACIjI1NSUvz8/AAAr1+//vHHHx8/fgwAuHjx4v3794VCNHUXIn2ohY68W0lJCQ6Hc3JyOnjw4M2bN7dt2+bu7l5TU2Nubt7TU0Qi8bmfqj+aamhio9G/YeFIPV9vPUjTzqO32QXEYjEOh0tOTk5NTY2Ojra2tt69e7elpWVkZCSBgFZ6QqQAFXSkGwKBIDMzE4fDBQQEHD9+/N69eytXrvTx8Wlra8NOyemji/tqXAO1nXze4ykKRygQXzlYO9Bbyy3ovUe23Lt3788//1y2bJmWltby5ctdXV0XL16M1X3ZhEWUHCroyF94PN7du3c7OzsjIyOvXbt29+7dWbNmDRkyRCAQEIkfPhrq4fXGV6XcgPH6SnmiTeatpsoidvDkAf/9h0hOTk5BQcH8+fNZLNacOXMCAgJWr17dy+AfBHkbKugqTSwWnz17trm5OTo6Ojs7+/r16+PGjRsyZIh0t9JQw3t4rUlLj2hqo2HjqqkEC0nXV/NelXEe327xHqk7ZJQuDi/lBnVVVVVFRUVoaCidTv/222/9/f0XLFhQU1Ojo6PTn3NGIgoHFXTVgv2cj4+Pf/Dgwc6dO7W1tWNiYkaMGOHl5SXrTdc85zzLbn9RzDa2ImvpEak0IkWbqKlNFAr/9QlsaGgwNDSUdZjeiUQiPP5f4wVwOFx7cwebKRQD8bOsdqoO0d6D6j6cJrsl9yR4PF5tba2dnd3t27e3bt26Zs2aiIiI4uJiDQ0NOzs7WW8dUSyooCs/bDz1li1bcnJy4uPjaTTa5cuX7ezsPDw8oOShV3Kb6B0spoDTJsDhcVzWP+M9ysrKDAwM9PT0oASTyMrKcnFxeXPwu5YuUSwGmjSCtp6amb2GJrypcVtbW3V0dFJTU48cORIaGrp48eLHjx+LRCIfHx90ZBVBBV05YV/7w4cPJyYmnjx50tLSMjk52c3NzdLSEna07olEooaGhvT09EmTJsHOAgAAMTExy5Ytg53iHbAe9szMzFOnTn3yySdhYWHnz5+n0WihoaGo5101oYKuJNhsNpfLNTAwiIuLO3r06OHDh729vQsLCy0tLXV0uj9pU37k5eV1dHR4eXn1dGYmLMeOHVu4cCHsFO/hwYMHKSkp06dPd3Z2PnToEI1GmzBhAup2Vx3oxCIFVl9fX1FRAQA4ePBgeHh4TU0Ndo5PZmamt7c3toqm/FdzOp1+8OBBPz8/eavmAABfX99FixbBTvEehg8fvmXLFmdnZwCAn59ffX39y5cvAQDfffddTEyMSCRCDTjlhlroCubFixd0Oj0wMDA1NXXXrl2rV68ODQ1lMBiSszQVy/Pnz9XU1KytrWEH6VFLS4uurm5+fr6npyfsLB/u6dOnmZmZs2bNYrPZixYtCgsLW7hwIRoTqXxQC10BPHv2LCkpCQBQXl6+du3aqqoqAEBAQMDNmzdDQ0MBAIpYzTs7O8PDww0MDOS5mgMAdHV1AQAFBQXnzp2DneXDOTs7z5s3j0gk0mi0bdu2WVlZAQBKS0vHjBlz9uxZAEBbWxvsjIgUoBa6nCouLi4oKJgxYwaLxVq8ePHw4cMXL14sFAqVYyRDR0fH8+fPBwwYAH2EYt/dunUrPDwcdgopq6+vr6ur8/T0zMjIWL9+/dKlS6dOndrU1IQmiVRQqIUuR4qKik6cOCESiQAAO3fuZDKZ2KzcZ8+eXbx4MTZrK+yMUnDkyBE+n+/i4qJA1RwAgFXz2NjY6upq2FmkxsjICOtKCgwMvH37to+PDwAgPz/f19f3119/xeZie3tFVkRuoYIOWXFx8cmTJ7HvTExMDJfLxebxOHXqVFRUFOx00peSkoLD4bS0tGAH+UCLFi1asWKFUtY4CoVib28PAAgNDX306JG/vz/2+QwMDLxw4QIAoK6ujs/nw46J9AZ1uUDw7NmzzMzMqVOnkkikJUuWuLi4REVFdTk1Uflg/UVVVVVy3mneFzwer7y83NXVFXaQflJXV2diYpKamvq///0vOjp66tSpNTU1BgYGZDIZdjTkX5S8iMiPysrKs2fPYkua7d27l8lkYjNexcbGLlu2TOmreXNzM9biU4JqDgAgk8lisfibb76BHaSfmJiYYC33hw8fhoSEYI2S0NDQxMREAEBNTU1Pqz4h/UzJ6whcjY2NV69ebWlpwfrE6+vrsRbN4cOHo6OjlaNDvI9u3bqVlZUFO4U0ubm5BQYGtraq3IrYRkZGAICRI0dmZGQMHz4cAFBYWDhixIgbN25gxR12QJWGulykjM/nZ2RkODs7GxsbR0VFmZiYrF27VpV/mSYnJ48dOxZ2ClkRCAQZGRmBgYH/ZYZh5YDNqnbp0qVt27bt2bNn2LBhvS+BgsgCKujSkZ+fT6VS7e3tV61aRSQSN27cKP+naPaDP/74o7CwMDo6GnYQGeLz+cOHD8/IyEA1XeL169cDBgw4cuTI2bNnjxw5MmjQoPr6eqxpj8gUKugfjsFgNDU1ubi47N+/v6CgYOPGjba2trBDyRes9Qo7RX94+fKlnp6e4o7ekRHJFEPr1q0rKSk5c+aMjo4Oh8OhUJRwtRN5gAr6eysuLnZ1df3zzz9/+OGHNWvWhISEYPPTws4lX7Zt27ZhwwbYKfpVenq6jo6O6gx9eV90Ol1HR4dCoQwbNmzo0KE7d+5sb29HfwKlCx0U7ZOmpiZssNrQoUOvXbuGHRNLTk7Gjvijat7F7du3fX19Yafob0FBQTt37lTKIepSYWpqijXM09LSFixYAACoqKgIDg5OSEjApoKAHVAZoBZ6b4RCIR6Pnz17dnt7+9WrVwUCgVgsRuX7nSoqKlR2MR0Wi4Wmq+279vb2yspKDw+Pe/fuxcfHL1q0KCgoCHYoBYYKevfi4+MTExMTExPJZPKzZ8+w+UiRd4qPj3dxcZH6qqSKZfv27dOmTcMmwEL6rri4uKmpacSIEefPn3/x4sWCBQsUa3IIeUD47rvvYGeQFy9evNi3bx8Oh7O2tmYwGIsXL9bV1cXhcAMGDIAdTTGcPXvWwsJCRY6C9iIoKGjHjh1ubm5vLmKHvJOhoSF23pmtrW1zc7NAILCwsIiNjW1ubrazs8OmxEB6h1ro4MGDB0QiMSAgICkpCY/Hh4eHo/FnCCInsrOzL1++PG/ePAcHh/v37/v5+anyWR3vpLoHRbFZxePi4q5cuWJqagoAmDBhQkREBKrmHyAnJ+fMmTOwU8gXFoulOnMDyI6Pj8/WrVsdHBwAACUlJaGhoc3NzWKxGB187pYqttAbGxtnzZo1Y8aMmTNnCgQCVMH/o1evXu3evXvPnj2wg8idoqKiy5cvb9q0CXYQpcLj8dTV1f39/efPn49NK41IqFBBv3btWlJS0tGjR5lMpkAgQMdbEEShPX78eMiQIbdv33727NmMGTMMDAxgJ4JP+btcampqsJUi8vLyli9fTiAQ9PT0UDWXlqtXr5aWlsJOIdfOnTunTGtiyA9sMFVISIiuru758+ex8bKwQ0Gm5C30U6dOXb58OSEhAY03kIXU1NTbt2/v2LEDdhC51tDQMGfOnFu3bsEOovxSU1O3bt16+vRpMzMz2FngUM6C/uDBg4KCguXLl5eWlg4cOBB2HKWFptPro/b2dqFQiOZr6wetra0sFsvQ0HDXrl2LFi1StX4YJexyKSgouHLlSmRkJAAAVXPZ4XA4aCnhPtLS0hKLxdhqsYhM6ejomJubq6urOzg4LF26FJsOE3ao/qM8LXQGg7Fjx47du3ez2WzUwSJrAoEgMDAwMzMTdhCFkZiYWFFRsX79ethBVE5OTk5qauqaNWuUfl0wpWqhJyQkzJw5EwCAqnk/SE9PR13n72Xy5MnYkDvYQVSOt7e3lZXV77//DjtIf1D4Fnp2dnZOTg4ajoogyDutXbt2/fr1StxVqNgtdDabHRcXN3/+fNhBVEt1dfW9e/dgp1A8LBbr0qVLsFOotMWLF//www+wU8iQAhf0jIwMAoFw5MgRNJ9tPzt+/DibzYadQvFQqdTExMTnz5/DDqK67O3t9+7dCwC4ePEi7CwyoagFfeLEic7OzmiaHiicnZ3DwsJgp1BIGzZs4HK5sFMgwNraWikPUCtkHzqDweDxeNhMmwiCIB+gsLDQ3d0ddgopU7wWen5+PoVCQdUclj///BN1BH8wgUCglA1DReTu7l5TU5OSkgI7iDQpWEGPj49PS0vT1taGHUR1PXjwAM1c+sGIRGJJSUlNTQ3sIAgAAJibmxcUFGDzwCgHRepy4XK5hYWFfn5+sIOotIyMDEdHR7SK0wfLzMy0srIyNjaGHQT5S1NTE41GU45ptBWpoCMIgkhdR0eHQCCgUCiwg0iBInW5fP75583NzbBTqLoNGzawWCzYKRTYjRs3lKzfVtE1NDRMmzYNdgrpUJiC3traWlFRoaenBzuIqsOWYIWdQoE1NDSgoehyxdzcnMvlNjU1wQ4iBQrT5dLW1kan052cnGAHUXWXLl2aOHEi7BQKrLy8nM1me3h4wA6CKCF5L+hTp07lcrnY1KM4HA6Px4vFYi6Xe+fOHdjRVMuYMWMIBAIO988HRiQS2djYxMTEwI6mGCZMmCAWi8ViMbYPsf+LxeIbN27Ajqa6wsLC1NXV8Xi8UCjE4XAAADweTyKREhMTYUf7QPL+23nEiBHHjx/vcqOFhQWkOKqrvr4e+8RLaGtrz549G14iBePo6Pj777932YdeXl7wEiGATCbT6fQuNy5cuBBSHCmQ9z70qVOnWlpadrlxzJgxkOKorqFDh775Y04sFjs5Ofn6+kINpUjmzZvXZZI/Go2mNMfiFNSECRO6/Im1tLTEJjpWUPJe0HV1dbtMG2Jubo6+Bv1v1qxZNBpNcpVGo82dOxdqIgXj7Ozc5URzGxubkJAQeIkQ8Nlnn3VZfTQ0NFShJ9eV94IOAJg2bdqbC1eOGzeOSqVCTaSKhg4d6ujoKGmku7i4oOb5+5o3b56uri52mUajzZgxA3YiVUelUt/8uW9lZTV9+nSoif4rBSjoNBotPDwcu2xpafnZZ5/BTqSi5s6diy1zjHrPP4yLi8uQIUOwy5aWlqh5Lg9mzJghmRhq5MiRkr+4CkoBCjq2fJeFhQWBQIiIiNDS0oIdR0UNHTrUwcFBLBYPGjRIUpiQ9zJjxgwjIyMqlTpr1izYWRCArVgZERFBIBAsLS2nTJkCO85/9e5RLp18UVNdB4cl7Jc8PSGNCpz5+PFjP7fxlcUwl1YgEHB6xmpaugqzpEZbc2dLfadQKJ3BqZ+ELWY1aI4fOUta7wKBgNM1UtPWU5X9qQGsfV0jGAyGtaHfB+9DPB7QDNR0DdU/7On9j90maKrrEHTK6QhpX9eIB7alXl5ezDoys05OV26hahP0jNWJ6u9ogr9jHPqDy6/L81maNKIGVd4HOPYPqi7x5VO2nom6f7ieoaVcL69Br+Rm3W5pbeiwGqTZ3iKn8yNq6RJflrB1jdR9R+ua2GjAjtMbxkte5m/NLYwOy0GaLKj7k6pDrHnOoeoQPUfQbN3k+nhSe0vn/UuN9dU8q0GanDa4jUIFRiDi2ls6O/kiRy+qX3hvx2x7K+i3TtbpmpBd/BW7U0kWOCxBSnzt2AXGesYk2Fm6V1/NSz3fMGq2GVmDADvLu3E5wjunasNmGg0wl9P92VjH/y2+PmyOqYamvLRshEJR6tm6wSE6tq6asLN0j9UquHKoNmSKCW2AwvyYkHO5qU1ALBoxsce5TntswN85W29goYGqebcoVOIny6yuHKSz2+Sx5dv6uuO3eEbEYkuFqOYAAA0KYfwSy+TjdW3NnbCzdIPVKrgWWzshylJ+qjkAgEDAh802y7nTUlsup2vandpcNX6JJarmUuQVqo8n4DOuNfb0gO4Lev0rHo8rchqiI8tsCs9//ICs2/I4+2P2nRb/8YawU7w3/wjDxynyuD+zUpoDxhvBTtE9/wjD3HstsFN0I/O3pqHjBuDxuD48FnkPniH69dX89pbumz7dF/Tmug6immIMgIFIW1+9pkweG0evSjna+orXLNI2UHtVKo/7s6aMq6Uvp4dtaQPUXz7lyOGMTPRKHlVxxg4oFhwe18zo6Pau7qs2u02gY6B4FaGfaeup4/A4sUi+vktCoViNhNfUlqPOgT6i0tTUSHihQL72p1gsJhCBlo78fh1MbTWYr+Wuq0osBNqooMuGngmpp2EO3Rd0kRDI2/dKHokB83UHTs5+VOJxOGaj3H29+6hV/vYnDodrfS2vA+4AAACwmAJ522lYo1DOmjrKo5MnEvUwYgj1qyAIgigJVNARBEGUBCroCIIgSgIVdARBECWBCjqCIIiSQAUdQRBESaCCjiAIoiRQQUcQBFESqKAjCIIoCVTQEQRBlAQq6AiCIEoCZkGfEBl6+syxD3vupu/WrV6zRNqJEARRSP+lmPSzyZ+FHz9xSEYvruQt9O++/+q329dhp0AQBOkPSl7Qy8pKYEdAEATpJ1Ir6J2dnXHHYiZ/Fh4+Nmj5igXFxQXY7S0tzVu3fztpysejwwNmzo68fPl8t08vKSmOXrnw4zGBU6aOOXxkX0dHBwDgwq9nwscGSR7T0FAfEurz6FFal+f2tImQUJ86Bv2nHd9HTAjGbkm+eXXOvEmjRg8d/8lHP279prm5Cbv9u++/+n7z+pPxh9/cnEq5fuPy1OnjRocHrPpycXV1VUioz70/7gAArlz9NXLiqIyM+5ETR8Ue3ou9C99vXj9+Qsio0UPnL/zszp2bkhdJunbxs2ljPx4TuHzFgrLnz0JCfe6m/gb1nwXH2zvtWenTNWujJkSGho8NWhI1OzsnU/LgoqL8RZ9PD/vYf+78yZlZD5evWLB333ao8SFgsVghoT6FhXnY1dTfb4eE+iRdu4hdxT6QJc+eYHd9sWRW+NigTyeFxRzcxePxJC8iEgljDu7CdvL/vl3DZLa+c7uFhXnRKxdGTAgeM27Y8hULCgpysdsFAkH8qSOz507ESookSS9v5YsXFSGhPg8fPpg7f/KSqNm9lEQAAB6PP3U67tNJYWEf+3+1IbqlRWoLdUmtoMce3pN882rUki/37okzM7NYt34Zva4WALDj581PnxT+b+PWY0fPTZ8292Ds7vSMP7o8t45BX7MuytTEfPfPh5cvW/vb7euxh/f0fdM9beLX8zcBAMuXrf3lTBIAICUl+eddW8JGjT1x7MLm73aWPX+24esV2FIvampqlS/Ky54/2751v7R2iAIpefZk956tAQEj4o4khH88/octX2PzgGN7hsfjXr5y/qt1302YMLmzs3PtV0tf1bz8YfOuk8d/HT7so63bv83IuA8AKCjI3btv+/BhoUcPn50+de6ePVsBAESi4q2z8d912Wl8Pv+r9cvV1NV/3nko9uBpZxf3/327+vXrBgAAn8//5tvVFE3NgzHxK6PXHzsWU1dXi+15lUKlUg0NjYqf/FXyCgtzDQ2Nior+qu8FhblaVK2BjoPS0//Y8uNGb2+/uKPn1q3d9CAtddeeHyUvcuu3ayKx6KftB9at3ZSX//idfxe5XO7X36y0trKN2X/yUMwpO1uH9V9Ht7W3AQAOH9l34dczM6bNO37swuRJM2IO/px88yr2fvX0VqqpqQEATp0++tmUWWvXfNtLSQQA3PvjDpPZsm3rvm82/vj0aWH8qSPS2pPS+b6x2ezkm1cXf74iJHgUAGD1qo1cDqe29pWpidnSqNV4PN7UxAwAYGFhlZSUmJ39Z1Bg8JtPT06+oq5OWrvmfwQCAQDA5XAK/34v+6KnTWhr0wAAFAqFpk0DACRePBsYOGLG9HnYw5YvW7t23dLi4gI3N08xAHR6zf59x7FHqpqUlBu6unpLl3xJIBAsLa0Z9XXlFWXYXTgcjsfjTZo4fahfIAAgPf2P6uqqo0fOOtgPBADMnbM4JzfrytULgYEj7ty9qaurt+SLlXg83tLSuq2NuX3Hd7D/ZXB02WkCgWDPriP6+gY0mg4AYP7cJZcvny9+UhASPOrRn2ltbcxVKzZYW9sCAKKXr4teuRB2fDgGew4pKs7HLucX5IwdE3kj+TJ2taAw18vLF4/HJ5yP9/DwWrRwGQDA3Mxi0cLlW7f9b9GCZYaGRgAAPV396GVrAQBOA53Ly0t/TfyFx+ORyeSettjQwGCz2aNGjrGysgEALFu6JnjEKHU1dRaLlXQtccb0eaNHj8M29Pz5s4Rz8WPHfEIgEHp6KwEOBwDw9PQJ/3h87yURAKCpSY1evg4AMNBxUFr6vZKSYmntRukU9Kqqio6OjkFOLthVNTW177/bgV3WIGsknI/Pz89mMltFIlF7e5uZmUWXp5eVlTg6OGHVHAAQFjY2LGxs37fel00IBIKKyuchIWGSWwYOdAYAlFeUubmDyK/QAAAgAElEQVR5YiVeNas59pPWxdldsv+HBYWcjD/85gOcnd2wC8/Ln5FIJHs7R8ldjo6DUlN/AwC8rH5hZ+uAx//1m8/F1aMf/wXySLLTiERip6Bz/4Ed5RVlLFY79qOwrY2J7XmqJhWr5gAANzdPrFKoIG8v3wMxO8VicWtrS23tqwnjJ51NOFHHoJsYmxYX58+YPl8kEpWVlcyds1jyFE8PbwBAZeVzrKC7uQ2W3OXi7C4QCOj0Gltb+562aG5uaWFh9eO2b8ZHTPLxGepgP9DT0xv7rSkQCHy8h0oe6eHhnXzzKofDoVAoPb2VGMmb3ktJxOJJLuvq6D3lFEljFwKpFfT29jYAAInU9Y+hQCBYt36ZUChctnSNpYU1gUD45tvV3T7d0ND4wzbdx01weVyxWEyhaEpuoWhQAABcLge7qqlJ/bAASqCtjalvMEByVfutP2ySncNis8hkjTf7BDQpmhwOGwDA4bD1dPUlt2O7V5VJdlpNTfXqNV8M9hzy9YYfDPQHiESiKVPHYHe1tTEpmppvPuvtna8ivLx821ntVVWVWMuARtMZONC5qDAPAFBfz/D29uPxeEKhMP7UkdNn4t58YlNzI3bhza8wWUMDAMDj9bbmOIFA2L/32Lnzp5KTr8QdizEyMp4/d0lY2Fjs87xq9WLJ5xwr3M0tTc3NjT29lV0y9FQSMRoaGpLLOKl2sUmnoNN0dLGvdJfbS0qKKyvL9+2Jc3f/648ns7XFxNj07ae//VxJN65ERwf/7cf0cRMaZA08Hv/mVtgctorXcQk1dXX+GweXsM9it6iaVC6XIxaLJW8Nm8PG9iGZrPHm94fFapdxaoXx+70UoVD4zcYfSSQSVp4kd5FIpDcP63Vp7qkUfX0DKyub4icFFRVlWFvbzdWzqDhfLBabmZqbmpiJRCIikfhp5NSxYz5584k6unrYhTc/flwOB/tM9r5RHR3dJV+sXPLFyqqqyl8Tf9n20yYra1vs87zx6y22Nv9q3RsOMDp/4XRPb2UXPZVEWZPOQVELcysymVxQ+NcxYpFItGLVotu3b/A7+G82Op48Kaxj0LE/d29ysB9Y8qyYz/+rXqekJEevXCgSiSgUTR6PJxD8tb61pGP3Te/cBHaZSCTa2zlKOukAAE+fFEo6XlScublladlTyU5LS7/X0yMHOjp3dHSUPX8mueXpk0InJxfsM1BR+VwkEmG3Sz4MSGdnB4lExkoAAODO3X/GBZmZWbS1MWvpNdjVoqL8vozNUFbe3n7FTwoKCnM9PLywgl5YlFdUnO/t7YeNDHFwcKqvr7O0tMb+MzExIxCJ2lra2NPf/HaXlj1VU1MzNTXvZXP0utr09L8GaFhb23656ms8Hl/1osLW1kFNTa2lpVmyIW1tGo2mo66u3stb2UVPJVEa+6k30inoVCo1/OPxZxNOpKQkl5aV7N6ztaysxNXN097OUV1d/fKV801NjY+z/9x/YMcQn6Gval52GaYzbuynAoHgx63fFBcXpKf/cSRuv5WlDR6Pd3QcBAC4eSsJ621MSkp8e9O9bIJEIpFIpILC3OflpQKBYPLkmX/+mf5r4i8MRl1efvaBgz97eHg5oYIOQPDwkfX1jJPxh+l1tXdTf3v46EFPj/T1DbCystm1a0vJsye19Jq4YzHPSp9OnjQDABAa+nFTU2PMoV0VFc9/v5dy/fql/v1HyK9BTq5MZuut3641NTVeTUp8VvpER0e3oqKMxWIN9QsikUgxB3+urq4qKsqPPbJXX98Adl5ovDyH5OU9fvnyhZurJ3YYpqamOjvnT6ygAwCmfjb7QdrvCefiX716+by8dOu2/0WvWMBm/9UKZjDop88cq6XXPM7+89r1S8OHh/ZyRBQA0FDP2PT9ul8Tf6murnr16uWZX47h8XhnZzcqlTpu3Kfxp478fi+FXlebl5+9Zl0UdoS/l7eyy4v3VBJlte/+JrVRZYs/X4HD4w8f3cflcmxs7Lf9uM/M1BwAsG7tpmPHYlLuJDs6Dvpq3XevGxt+2LLhyzVfnDz+q+S5RkbGP207cPjovtVrl2hr04KDRy1asAwA4OjgtHDB0tNn4o7G7bexsY9evu7zxTMkbUCMjo5uL5uYNnXu+QunHj1K++XM1ZGhH/P5vF8Tf4k7FqOpSQ0KDF68eIW0/vkKLSBg+Px5Sy5fOX/xUoKHh/eXq77+fPEMkjrp7UcSicQd22MOxe5e99VSHo9na2P/w/c/ew0eAgAY4jM0asmqC7+euXHjsoOD09Ko1Su//BzGv0buBAQM/2zKrCNH9x+K3e3nG7h+3fcXL509d/4UHo9fuWL9pv9tPxi7e+Hn02xt7JctXbNz1w/q3e15VeDh4d3c3GRhYaWjowsA0KJqWVvbvnhR4enpgz1g+LCPvt7ww7nz8SfjD2tqUl1dPfbsOqKpqQkAEAoFM6bPYzDoS6Jmd3Z2+PkGroj+qvfNeXp6f7V2068XfzkZf5hAIFhZ2f7w/c8WFlYAgKgvVmlRtY7G7W9qatTT0w/wH75g/tLe38pJk2Z0ef2eSqJM4d7uAAEAZN1u7uABj2A9WW9eoYlF4MwP5Ut393gYHQqxCBxaUz5703ukEovFzc1NkrZhYWHeilWLThy7YGNj98ExmMzWTz4duenb7cEjRvb9Wac3ly/ZaY+Xs/OXD64un/mNrFIx25jkv3/Fd3R0TIj86PNF0ZGfTOn7K1w58HLCF6Y0AzWZ5PtQZ358+dF0U209+UqlHDJvvjY0V3cf1s3xc1U87wPpoqAgd9XqxfPmfvFRSFhra8uh2N1OTi6SsXSI7LBYrJmzJngN9p09axEOh7uQeAaPxw8f9hHsXIiiQgUdAZ6e3hu++v5C4pmEcyepVC1PD+/Fn69QwfMV+x+VSv1pe0xc3IHolQvwOLydvePOnw6qcje6dBUV5X/9zcqe7v3lTJLynXqCCjoCPuBkrnei0XTupWZL8QWVlfMg1z27pXbmN/ImR8dBR48k9HSvFlWrf+P0B1TQEQRRTiQS6e1TUpSbnB1+QhAEQT4UKugIgiBKAhV0BEEQJYEKOoIgiJJABR1BEERJoIKOIAiiJFBBRxAEURKooCMIgigJVNARBEGURPcFnUwhENXQVB7vIBKJja3fsSRK/8PhgJEVudtJNOWcWCw2tCTj5e9zZ2ytIRbJ7/6kDVDHE2CHeIueMQko4IdQIahr4NXJ3Zfu7m+lGRDrqnpbjg8BADTSefJYN3FA0CFuZnSzXJ+ca6rjiwRiIH8FXSQUN9Xx+vBACHgcYUM1V0tX7mapJaqBRrrifQgVQu1zjp5x9+949wXd3IHSwRXKOJXCe/2KZ+8hj0uS2ntqNryS0wLUi4ZXPHtPedyfdh6ar+V1fzKquAN95HGSKRtXzeY6VNClj88VqpPxhhbdL8bUfUEnEHF+H+ulnK6VcTYF9jyXyajieAbrwA7SDZ9Rei+fsKqeKNIyzS+K2l+VsLxDdWEH6YZXiC69glNe0OPa2bA0M/g5txuHRw6AHaQbjl5agk5h/v0m2EGUzd2z9KAJ+j3d2/2KRZjaCu7t0wzPEXo6RiSKFpqXESNurOW3NXXUVXImRst8QakPJhaLE/fUWDhpaumpG5j2trIibOJGOr+9uaOmlDNppZk8T8J+cV+NqT1FW1/dwJQEoHYM4XCgmcFntXaWZDKnf2VBVJPfoQ13E+oJ6gR9E5KBGRkvh4dHFAQOB9pbOtuaOrJ+a5y80lzfpMdFCnsr6AAAVqsg9/cWRhWP0w65B0YkEgkEAnV1dbgxDMzIeLzYahDFxV8BpsYvSm+tLuWKxaCxVmo/fnk8Xu9r774XAzMyDie2dNJwC5TH3zpdFD9kvizh/Mf9KRQKxGJAJH54C0nXWB0HgIWjxuAQefxB00VZbntlEbuzQ9wkx13qHR0dRCIRL2+LH/5NjYQnaeBNbck+YXrqpN5CvqOgy4+srKyTJ0/GxsbCDqLqfHx8srPRyhUf7ty5c7W1tWvWrIEdBPlHVFTUnDlz/Pz8YAf5r+T0LxKCIAjyvlBBRxAEURIKU9CJRKKZmRnsFAjw8vKCHUGxaWho6OoqQN+3SjEzM/svRzXkh8IUdLFYrCjd/cotNzcXdgTFxuVyW1paYKdA/kUkEsGOIB0KU9CpVGp7uyINrFZWgwYNgh1BsZFIJBpNAYZIqRQ2m62hIXfTeHwAhSnoxsbGTCYTdgoEVFZW8nhyetqkQmAymXy+/A7gU01MJtPExAR2CilQmIJOo9E0NTUZDAbsIKrO09Ozo6MDdgoFpqampq/f45l+SP9jMBhKc2BDYQo6AMDJyQmNgIaurq4OdQH/F69evVJTk7u5tFRZZmams7Mz7BTSoUgFfcSIESkpKbBTqDonJ6e2Nrmb1USBEAiEAQPkcfYVlZWSkvLRRx/BTiEdilTQBw4cSCQS79+/DzuIqqPT6bAjKLAnT56gLhf5cfv2bRqNZmtrCzuIdChSQQcAbNiwIS4uDnYKlWZubl5TUwM7hQKrqakxN5ffad1UzdGjRzdu3Ag7hdQoWEEfMGDA1KlTUU2HyN7ens1mw06hqFgsloODg46OAsxEpgr27t27dOlSTU1N2EGkRsEKOgBg3Lhxra2tFy9ehB1ERdnZ2aWnp8NOoaiePHkit1P6qZrvvvtOR0dHaXrPMQr52Vq7dm1ubm5SUhLsIKrIzs6upqYGjaT+MCUlJejMLHlw/Pjx4ODguXPnwg4iZQpZ0AEAW7duFQqF+/btgx1EFQUGBhYWFsJOoZBKS0u9vb1hp1B1W7du7ezsDA4Ohh1E+hS1oAMAPv30U7FYfPDgQdhBVI63t/cff/wBO4XiEYvFd+7cCQgIgB1EdfH5/KioqIEDB37xxRews8iEAhd0AMDKlSttbGwiIiJevnwJO4sKCQoKQt3oHyA9PT0oKAh2CtWVmpoaEhISFRU1ceJE2FlkReFnjBwzZoynp+fGjRuDgoIWLFgAO45KMDc319XVffr0qdKcX9c/UlJSwsPDYadQRRwOZ//+/c3NzQ8fPoSdRbYUu4WOMTU1PXnyJJ/Pj4yMfPLkCew4KiEyMhINNHovHA7njz/+GD16NOwgKicxMXH06NE+Pj47duyAnUXmFGZN0b6orq4+ceIEl8tdtWqVsbEx7DhKLjAwMC0tDQ3C66OzZ882NjauWLECdhAVkpKSsn///tGjRy9fvhx2ln6iVAUdc/fu3T179nz66aeTJk1CE0/LzqFDh0gkEurm6qPQ0NBLly6hU4r6R3p6emxsrKWlZXR0tHLMi9tHSljQMVevXt2/f39YWNjChQsNDAxgx1FOfn5+GRkZyrF2l0ydPn26paUFNc/7we3bt0+cOGFpablgwQInJyfYcfqb0hZ0TGJi4rFjx4YPHz5x4kQVfHdl7dy5cw0NDahOvdOwYcPS0tJgp1BmAoHg119/zcrKolAo8+fPt7e3h50IDiUv6Jhbt2798ssvGhoa06ZNCw0NhR1HqUyePPmnn35SmsnqZGHLli0uLi6RkZGwgyinioqKCxcuJCUlTZkyZdq0aaamprATwaQSBR2Tl5d37ty5Fy9eBAYGjhs3TmX/hktXVVXV6tWrL126BDuInHr48OG5c+cOHDgAO4iyaWtru3nzZnJyspaWVmhoqBIPLX8vKlTQMS0tLTdu3Lhx44aamlpERMS4ceOUaa41KE6fPs3n8xctWgQ7iDwaO3ZsYmIihUKBHUR5pKSkJCcnFxYWjhkzZuzYsehkiDepXEGXKCkpuX79+o0bN3x9fSMiIkaMGAE7kQJbvnz5tGnT0EntXSxbtmzGjBn+/v6wgyiDnJyc5OTk5OTkjz76aOzYseic226pbkGXuHfv3vXr13Nzc2fOnOnj4+Pp6Qk7kUL6+OOPz5w5gxZXk9i3b5+uru7s2bNhB1FsT58+ffz48YULFywsLLAmORpV1QtU0P/S3t6empp6/fr16urqkJCQ0NBQPz8/2KEUSUtLy+rVq0+cOAE7iFxITU3Ny8tbs2YN7CCKKisr648//rh3756BgcHYsWNDQkKMjIxgh1IAqKB31dzcfO/evdTU1KKiIqyyo96YPiovL9+4ceOFCxdgB4EsKyvr5MmTsbGxsIMoGKFQ+MffXF1dg4ODQ0JCDA0NYedSJKig94jD4WCVPS0tDavsoaGh6Ode73Jzc2NjY1V5jcCCgoIdO3acPXsWdhCFwWQyscb4w4cPg/+GDiN/GFTQ300kEmGVvayszNDQMCgoKCgoyNLSEnYuOVVVVbV79+79+/fDDgLBkydPLl68uGnTJthBFMDTp08fPXr0/PnzrKwsrDE+bNgw2KEUHiro7yczMzM9PT09PV0sFgcGBgYFBaExDG/Ly8uLi4s7dOgQ7CD9qrS09Ouvv0ZD8nvR2tr68OHDhw8fPnr0yNTU1N/fPygoyN3dHXYu5YEK+gd69epVRkZGenp6ZmYmVtkDAwNVahqg3mVmZiYkJKjOGoFFRUXbtm1LSEiAHUQe5efnY0WcTqcHBAQEBAT4+/ujecpkARX0/0okEmGVPSMjg0KhBAYGBgYG+vj4wM4FX0FBwebNm1WhxZqSkpKenr5582bYQeQIg8HIzs5+8ODBo0ePHB0dsSKOTgKSNVTQpamioiIjIyMvLy8tLc3X19fPz8/Pz0+VJwWrqqqaNWvW7du3lfgY19mzZ4uLi7dt2wY7CHxtbW2PHz/OzMzMysrCVmH28vLy9/dX4ndf3qCCLhNisTgrKyszMzMzM7Ourk5S3FVw5iAOh7N27dqoqCgXFxfYWaRv586dBALhyy+/hB0EGoFAkJWVlZWV9fjxYzqdPmTIED8/P19fXwsLC9jRVBEq6DLHZDIlxR2Px/v9jUqlwo7Wf2bPnv3ZZ5+NHTsWdhBpWrJkSUhIyJQpU2AHgSA/Px+r40VFRb6+vr6+vkOGDFHlH6NyAhX0flVTU4NV9pcvXxKJRB8fnyFDhnh7e2toaMCOJnPffvutubn5559/DjuIFLS0tGzevHnatGm+vr6ws/SfgoKC3Nzc4uLijIwMFxcXrI4PHjwYdi7kH6igQ/Ps2bPs7OzHjx/n5OTY2tr6+Pj4+Ph4e3uTSCTY0WTl3LlzaWlpij6cMTMzc+PGjefOnVP6iWvEYnFubm5ubm5OTk5ubq6rq6uXlxf2KVVTU4OdDukGKuhy4cmTJ9nZ2dnZ2Tk5OY6OjpKWu/KdmIoNZ1y7dq25ubnkxkmTJl28eBFqrr46fvx4SUnJzz//DDuIrAgEgpycHKyC5+fne3l5eXl5eXt7e3l5EQgE2OmQd0AFXe4UFRVJWu4ff/yxoaHh4MGDvby8yGQy7GjSwWQyZ8+evWrVquDgYOwWLy+vCRMmyNsJlo2NjfPnz+dwOHfv3sVu2bBhg4WFRVRUFOxoUsZisfLy8srKytLS0kpKSry9vbEKjrpTFA4q6HKtqKjo8ePHeXl5ubm5NjY2WHPJ09NTCU7K2Lt3r1AoXL169dChQwUCgZmZWWxsrFyNAoqNjT116pRAIDA2Nj527NicOXO++eYbpTk9ncFg5Ofn5+bmFhQUMBiMwYMHY+PE3dzcYEdDPhwq6AqjpKQE69DMz8/X09MbPHiwt7f34MGDFXc6uoSEhD179kg+gVOnTpWf+WbZbPacOXOqqqqwrmRjY+NTp04ZGBjAzvWflJeXYwc28/PzAQCenp5eXl4eHh5oOUalgQq6QqqsrMzLy8vJycnLyzMyMrK0tBw8eLCHh4diLdb86aefVldXS66am5ufOHFCT08Paqi/xMfHx8XF8fl87KpYLM7JyYEd6r0JhcKCgoLCwsKysrKMjAxjY2MPDw/sR56xsTHsdIj0oYKu8Oh0el5eXl5eXkFBQWNjo+ffPDw8YEd7hy4TJBCJxEWLFi1YsABeor+IxeIpU6a8ePHizRvJZHJ6ejq8UH31+vXrwsLC/Pz8wsLCkpISDw8Pd3d3rCWuUqc+qCZU0JVKW1tb/t8KCws9PDw8PT0HDx7s6ekpb1/mkJCQtrY2bDIcyfAJCwuLc+fOQT/8e/HixQMHDrDZbOwq9h3R19fX0tKSz6lpSktLCwoKsMZ4Z2enu7u7p6enu7u7q6sr7GhIv0IFXZlhlT0vL6+kpIRGo0m+51ZWVrCjAQDA5cuX8/LyyssquRwRl8Pl8Xjq6uqzZs2KjIyEG+zzzz+n0+lqamra2tp4vNjc2nDw4MG2trbyc0S0vb29sLAQq+A4HI7JZHp4eGCNcbk6sIz0M1TQVUVlZaXkl7jk+4814fs5iVgkfvGEXVHAbqrvaG3oEAmBgTm5tYEnFAlFQiGZDP+kWS6Xg8cTCAQCHo9XJxPbmzvImgQTOw1DM3UbV00DUzhnflVWVhYVFWFFvLGx0d3dHavg7u7uSnwyGvJeUEFXRa2trQV/w+PxAoFA0njX19eX3Xa5bOGj5Oanj5h6ZhQNHQpFl0RUJxKIeNltUSrEYrGgQyjgC1mNbHYTV0uP4OyrNchXW9bb5XA4RUVFhYWFdXV1qamphoaGbm5uWBG3sbGR9dYRRYQKOgIKCwsljXcNDQ1J4/2do9kiIiICAgI2bNjQl62kXWl8mtlm7KhHM9GSUnA4OniClpctPBZ/xKcG1s6afXnKsmXLYmJi+vLIqqoqrIgXFhbS6XQ3NzfskKazs7O8HQVB5BAq6Mi/1NTUSBrvDAZD0nL38PBQV1fv8uDg4GA+n+/l5bVr165ejmSymMLEva+0jbT0rRT+fCgJPrujjdGub4T/aHJvg9MbGxvXrFlTXFycnZ3d7QN4PF5hYSHWl1JUVKSnp4cVcXd3dzQ8HHlfqKAjPWKxWJKWe0FBgZ2dnaS+Y6OYvb29cTicUCgcOHDgli1bui1ALQ0dF3bV2A01UyMr27w0AIDm6la8iP/Jku6PQ2ZlZe3evbusrAyPx5uYmFy/fh27vbq6uvBvr169cnd3x/pS3NzctLVl3pODKDFU0JG+KikpkdR3AICHh0dKSorkXktLy+XLl4eEhLz5lJb6jlunX5u6KvM5LMy6drJ6x+iZXc/XTUxMPHPmDJ1Ox65qaGjMmzcPa4xra2u7/83BwQFGakQ5oYKOfAgGgzFz5szW1tY3bzQ2Np48efKcOXOwq3yu8OR3L52C5WKIpEwxGe1kIn/0LCPJLTt37rx7925TU5PkFrFYPH/+fKwxrgRT8SDyCRV05AOFhYU1NzdLrmIfJCqVev/+feyWU5tfmroZK2VPy9saXzTZDVIbHKILAJg/f/6zZ894PB4e/88AHgWdPABRLCrxZUNkoaWlBatTZDJZV1fXyMho4MCBgYGB2L1pVxq1jLVUpJoDAAxs9HNSqx0Ga1F1iGPGjNHX16+srGSz2S0tLQKBAIfD4XC4CRMmJCUlwU6KKDPUQkc+0OjRo21sbFxdXX18fJycnN7sRuCyhGd+fOk4XPk7W97EZLDUcdzwuf8cMKisrHz69GlmZmZlZWV7ezuXy71z5w7UjIiSQwUdkb7U8w3tHHUdBR9v/gFe5dHD5xgamKHzNhE45P0kPUThiITiZ1lt8lzNdx6Ydvn6Tlm8MkWfWvSwTRavjCB9gQo6ImUvnrB1TSmwU8ChbUipLGLBToGoLlTQESmrKGRr6KhoQVcjEwlEQmMtH3YQREWpyiAEpN801XXo2cjqdEehUHD3/sn8ojstrXU6NKPhAdMCfCcCAOobXuw8MPWLeYfSHp1/UV2Ax+E9XEeOD1+FzbRe+TL/yo2fGxpe6Omaho9cIqNsGIoeub6ah7rREShQQUekjPm6w9BJVp+rG7cPZGZfjYxYZ2PpXlaRlZS8m4An+vlMIBCIAICkW3smRqybZ7nzecXjI/HLbKw8Pd1Gcnms+LNrTYwdViyJFwo7k1MOtrc3yigeAACHw7e3CGT3+gjSC9TlgkhTJ18kFgMZzYjL5bEeZl4cETRzyOCxBvoWAb4TfQaP/T3ttOQBHi4fWVu6AwAc7Ibo65rV1JYAAErKMjjctshxa0yNHSzMnKd+uonDleFxS4I6sb1VKLvXR5BeoIKOSBOnXaBvJqsVKuh1ZUKRwNHOV3KLnY1XU3MNn8/BrpoY/zMvCpmsxeW1Y70xampkY8O/ls/WoRnStLvOuyJFamQCDoeT3esjSC9QlwsiTZraxMYaruFAmbw4VrgPn4gC/1RMMQCgnfXXlClqxH/1XIuBGHuWutq/pvYlkWR4zLaTJyBronM7EDhQQUekiaiOxxNwwk4RQU36P/7IZE0AwPTJm02M7N68nUYzYjLre3qWuhqZx/vXUEIut13q2SQEfKG2OUF2r48gvUAFHZEyPROSoEMoi4JuYuxAIKixWM2GrqHYLSx2CwA4NWLXlTfeZDjASigSMBoqsV6XuvpySYteNsRaemqyfH0E6REq6IiU6Q5Qa2/hkjSlX9Q0yFT/IZG378VpaupYmDm3tDKSbu3RoRkumLm7l2c5OQaS1ClXb/w8JmypUNh5804slaon9WwS7a85xtY02b0+gvQCFXREyuw9NdNvtOqZy2QoesTHKzTIWskpMW3tjVpUfeeBw8JHvWNcOVVTZ+70HVdv7j547HNdHZMxI6MePDqPdb5LHZ/TiceJ9Yx6+8WAILKDJudCpC9mVbnLKGsVHOzR9JJpMEA4YuIA2EEQFYWGLSLS5+JPa6mR4YFHudVa2+Y5Aq1GhECDulwQ6Qv6RD9u4ws9ix57XfYcmt3UUvv27SKREIjFeEL3H8sNqy5rUqTWPf37g1NvnpT0JhzAiXvok1m/8hJVs/uS3VLbZulEoRmgI6IINKjLBZGJP28111SJDay7r32tzAaRqJvz4zs7+WIA1NW6nwhFh2b85qJu/xGX246defQ2DredotH99L80bSNsfpi3PU9/OXODpQYVNZIQaFBBR2TlzNbqAfYDyFoqcYSQUfrazff0KSYAAAFnSURBVI/i4i+rWckQpC9QHzoiK7O+tix/1E2/ivJpqm41Niegao5Ah1roiAyx2wRXDjHM3IxxeKUd8dJY1WpkDIZF6sMOgiCohY7IkqY2MXKJ8dPUKm6bcq758LqiSYsqQNUckROohY70h/O7XuHUyUb2MjxFs5+xW3icpnY7F7LXR2icIiIvUEFH+snjlJbMW02mTno0EypBTYGnr+K2dzS9aCYSxSMm6ptYy2quYAT5AKigI/0q43pTcQZTQ0uNoqdJ0SUR1QhEEgFPkOuuP0GHUMAXCjoF7Q0c1muOkTXZLVDbxkUTdi4E6QoVdAQCeiW3ooDdUMNnNnXyWEJ9M3JLvZx2squp4YUCEZlKNLYmm1qTbFw1NWlopDkip1BBR+Dr4Irk9lNIVMMRiEo7RAdRMqigIwiCKAm57rtEEARB+g4VdARBECWBCjqCIIiSQAUdQRBESaCCjiAIoiRQQUcQBFES/wdJCMC9ZwFzZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display  \n",
    "\n",
    "try:  \n",
    "    graph_image = final_graph.get_graph().draw_mermaid_png()  \n",
    "    display(Image(graph_image))  \n",
    "except Exception as e:  \n",
    "    print(\"Error:\", e)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: A time series is a sequence of\n",
      "data points, measured typically at successive times, spaced at uniform time intervals. It can be thought of as a list of observations recorded over time. Time series data can come from various sources, such as economic indicators, weather patterns, stock prices, or sensor readings.\n",
      "\n",
      "Time series analysis involves the study of time series data to extract meaningful patterns, trends, and relationships. This analysis can help in forecasting future values of the time series, understanding the underlying factors driving the data, and making informed decisions based on the insights gained.\n",
      "\n",
      "Time series data can be univariate, meaning it consists of a single variable measured over time, or multivariate, meaning it consists of multiple variables measured over time. Time series analysis techniques can be divided into two categories: time-domain methods and frequency-domain methods. Time-domain methods focus on the time-based relationships between data points, while frequency-domain methods focus on the frequency-based relationships between data points.\n",
      "\n",
      "Some common time series analysis techniques include moving averages, exponential smoothing, autoregressive integrated moving average (ARIMA), and state-space models. These techniques can be used to model and forecast time series data, as well as to identify and analyze trends, seasonality, and other patterns in the data.\n"
     ]
    }
   ],
   "source": [
    "response = final_graph.invoke({\"input\": \"What is Time Series?\"})\n",
    "print(\"Output:\", response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @graph.add_entry_point()\n",
    "# def start(state):\n",
    "#     return route_query(state)\n",
    "\n",
    "# graph.set_finish_node(\"calculator\")\n",
    "# graph.set_finish_node(\"web_search\")\n",
    "# graph.set_finish_node(\"rag\")\n",
    "\n",
    "# # Execute the Graph\n",
    "# app = graph.compile()\n",
    "# response = app.invoke({\"input\": \"What is the leave policy?\"})\n",
    "# print(\"Output:\", response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversational_agent = initialize_agent(\n",
    "#     tools=tools,\n",
    "#     llm=llm,\n",
    "#     agent='chat-conversational-react-description',\n",
    "#     verbose=True,\n",
    "#     max_iterations=5,\n",
    "#     early_stopping_method='generate',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     result = conversational_agent({\"input\": \"What is Time Series\",'chat_history':['']})  #Pass the input using dictionary structure\n",
    "#     print(\"Final Output:\", result[\"output\"])\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:364: UserWarning: WARNING! system_prompt is not default parameter.\n",
      "                    system_prompt was transferred to model_kwargs.\n",
      "                    Please confirm that system_prompt is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'system_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 214\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m    213\u001b[39m session_id = \u001b[38;5;28mstr\u001b[39m(uuid.uuid4())\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m response = \u001b[43mfinal_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is Time Series?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput:\u001b[39m\u001b[33m\"\u001b[39m, response[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2367\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2365\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2366\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2367\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2368\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2371\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2372\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2024\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2018\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2019\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2020\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2021\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2022\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2023\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2031\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    228\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m config = patch_config(\n\u001b[32m    543\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    544\u001b[39m )\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    548\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 190\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    188\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mweb_search\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m state: {\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: web_search_tool.run(state[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m])})\n\u001b[32m    189\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mrag\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m state: {\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: rag_tool.run(state[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m])})\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mgroq\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m state: {\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43moptimize_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muuid\u001b[49m\u001b[43m.\u001b[49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m    193\u001b[39m graph.add_conditional_edges(\n\u001b[32m    194\u001b[39m     START,\n\u001b[32m    195\u001b[39m     route_query,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m     }\n\u001b[32m    202\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36moptimize_response\u001b[39m\u001b[34m(input_text, session_id)\u001b[39m\n\u001b[32m     62\u001b[39m messages = session_memory[session_id][\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     63\u001b[39m messages.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: input_text})\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m messages.append({\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: response.content})\n\u001b[32m     66\u001b[39m session_memory[session_id][\u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m] = response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:285\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    275\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    276\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m     **kwargs: Any,\n\u001b[32m    281\u001b[39m ) -> BaseMessage:\n\u001b[32m    282\u001b[39m     config = ensure_config(config)\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    284\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    295\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:861\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    854\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    855\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     **kwargs: Any,\n\u001b[32m    859\u001b[39m ) -> LLMResult:\n\u001b[32m    860\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:691\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    689\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    690\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    699\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:926\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\Desktop\\share\\lang\\one\\venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:480\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    476\u001b[39m params = {\n\u001b[32m    477\u001b[39m     **params,\n\u001b[32m    478\u001b[39m     **kwargs,\n\u001b[32m    479\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[31mTypeError\u001b[39m: Completions.create() got an unexpected keyword argument 'system_prompt'",
      "During task with name 'groq' and id 'd090b195-8d33-d206-1b64-82b219afbc7d'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: A time series is a sequence of\n",
      "data points, measured typically at successive times, spaced at uniform time intervals. It can be thought of as a list of observations recorded over time. Time series data can come from various sources, such as economic indicators, weather patterns, stock prices, or sensor readings.\n",
      "\n",
      "Time series analysis involves the study of time series data to extract meaningful patterns, trends, and relationships. This analysis can help in forecasting future values of the time series, understanding the underlying factors driving the data, and making informed decisions based on the insights gained.\n",
      "\n",
      "Time series data can be univariate, meaning it consists of a single variable measured over time, or multivariate, meaning it consists of multiple variables measured over time. Time series analysis techniques can be divided into two categories: time-domain methods and frequency-domain methods. Time-domain methods focus on the time-based relationships between data points, while frequency-domain methods focus on the frequency-based relationships between data points.\n",
      "\n",
      "Some common time series analysis techniques include moving averages, exponential smoothing, autoregressive integrated moving average (ARIMA), and state-space models. These techniques can be used to model and forecast time series data, as well as to identify and analyze trends, seasonality, and other patterns in the data.\n",
      "Output: Time series analysis has a wide range of use cases across various industries and applications. Here are some examples:\n",
      "\n",
      "1. Economic Forecasting: Time series analysis is widely used in economics to forecast economic indicators such as GDP, inflation, unemployment rate, and stock prices. Economists use time series models to understand the relationships between economic variables and to make predictions about future economic conditions.\n",
      "2. Weather Forecasting: Time series analysis is used in meteorology to forecast weather patterns such as temperature, precipitation, and wind speed. Meteorologists use time series models to analyze historical weather data and make predictions about future weather conditions.\n",
      "3. Sales Forecasting: Time series analysis is used in business to forecast sales revenue, product demand, and customer behavior. Business analysts use time series models to analyze historical sales data and make predictions about future sales trends.\n",
      "4. Quality Control: Time series analysis is used in manufacturing to monitor and control the quality of products. Manufacturers use time series models to analyze production data and identify trends or anomalies that may indicate a problem with the production process.\n",
      "5. Financial Risk Management: Time series analysis is used in finance to analyze financial data such as stock prices, interest rates, and exchange rates. Financial analysts use time series models to identify risks and opportunities in financial markets and to make informed investment decisions.\n",
      "6. Healthcare Monitoring: Time series analysis is used in healthcare to monitor patient health and to detect anomalies in physiological signals. Healthcare professionals use time series models to analyze patient data and identify trends or patterns that may indicate a health problem.\n",
      "7. Social Media Analysis: Time series analysis is used in social media analysis to analyze user behavior and to identify trends in social media data. Social media analysts use time series models to analyze user data and make predictions about future user behavior.\n",
      "\n",
      "These are just a few examples of the many use cases of time series analysis. Time series analysis is a powerful tool that can be used to analyze and forecast data in many different contexts.\n",
      "Output: Assuming you have a database schema with two tables, `users` and `orders`, where the `orders` table has a foreign key `user_id` that references the `id` column in the `users` table, and the `orders` table has a `created_at` column that stores the date and time when each order was created, the following SQL query will retrieve the users who have placed orders in the last 30 days:\n",
      "```vbnet\n",
      "SELECT u.*\n",
      "FROM users u\n",
      "JOIN orders o ON u.id = o.user_id\n",
      "WHERE o.created_at >= NOW() - INTERVAL 30 DAY;\n",
      "```\n",
      "This query joins the `users` and `orders` tables on the `user_id` and `id` columns, respectively, and filters the results to only include orders that were created in the last 30 days using the `WHERE` clause. The `NOW()` function returns the current date and time, and the `INTERVAL 30 DAY` expression subtracts 30 days from the current date and time. The resulting set of rows includes the user data for all users who have placed orders in the last 30 days.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

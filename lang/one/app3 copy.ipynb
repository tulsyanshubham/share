{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU \"langchain[groq]\" sentence-transformers duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import uuid\n",
    "from collections import defaultdict\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools import Tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session memory to store previous messages and state\n",
    "session_memory = defaultdict(lambda: {\"messages\": [], \"state\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant designed to handle various tasks including:\n",
    "- Answering general knowledge questions.\n",
    "- Performing mathematical calculations.\n",
    "- Retrieving real-time information from the web.\n",
    "- Providing research-based answers from the vector database.\n",
    "- Handling natural language queries efficiently.\n",
    "- Use the appropriate tool to generate sql query.\n",
    "\n",
    "Instructions:\n",
    "- Always keep the response concise and clear.\n",
    "- If the user asks for real-time information, prioritize the web search tool.\n",
    "- If the query relates to mathematical expressions, use the calculator tool.\n",
    "- If the user seeks in-depth or document-based information, use the RAG tool.\n",
    "- For everything else, generate a response using the LLM.\n",
    "\n",
    "Be accurate, helpful, and concise.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the API key is already set\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatGroq LLM with the system prompt\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define table schemas\n",
    "table_schemas = \"\"\"\n",
    "Table: Users\n",
    "    Columns: id (PK), name, email, created_at\n",
    "\n",
    "    Table: Products\n",
    "    Columns: id (PK), name, price, created_at\n",
    "\n",
    "    Table: Orders\n",
    "    Columns: id (PK), order_date, total_amount, user_id (FK)\n",
    "\"\"\"\n",
    "\n",
    "# Function to convert natural language to SQL query\n",
    "def nl_to_sql(text: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following natural language command into an SQL query.\n",
    "    Use the following table schemas:\n",
    "\n",
    "    {table_schemas}\n",
    "\n",
    "    Command: {text}\n",
    "\n",
    "    Provide only the raw SQL query without any explanation, \n",
    "    additional text, or escape characters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate SQL query using optimize_response\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "# Create the tool\n",
    "nl_to_sql_tool = Tool(\n",
    "    name=\"Natural Language to SQL\",\n",
    "    func=nl_to_sql,\n",
    "    description=\"\"\"\n",
    "    This tool strictly converts natural language commands into raw SQL queries \n",
    "    based on the provided table schemas without adding any explanation, assumptions, \n",
    "    or additional context. The output must be a valid SQL query only.\n",
    "    \"\"\"\n",
    ")\n",
    "# print(nl_to_sql_tool.run(\"Generate a sql query for users who have placed orders in the last 30 days\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchRun()\n",
    "# search_tool.invoke(\"who is the president of the united states\")\n",
    "\n",
    "def search(text: str) -> str:\n",
    "    return search_tool.invoke(text)\n",
    "\n",
    "web_search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=search,\n",
    "    description=\"Search DuckDuckGo for real-time information.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 7\n"
     ]
    }
   ],
   "source": [
    "def calculator(inputs: str):\n",
    "    try:\n",
    "        return str(eval(inputs))  # Simple arithmetic operation\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "calculator_tool = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator,\n",
    "    description=\"Performs basic arithmetic calculations. Input should be a mathematical expression.\"\n",
    ")\n",
    "print(\"Sum:\", calculator_tool.run(\"2*3+1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain_community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "def load_document(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_document('./data/temp.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = \"postgresql+psycopg://postgres:postgres@localhost:5431/vectordb\"\n",
    "collection_name = \"my_docs\"\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_into_vectordb(splitted_texts):\n",
    "    documents = []\n",
    "    ids = []\n",
    "    for i, text in enumerate(texts):\n",
    "        ids.append(i)\n",
    "        documents.append(Document(page_content=text.page_content))\n",
    "    vector_store.add_documents(documents=documents, ids=ids)\n",
    "\n",
    "store_into_vectordb(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_tool_func(text: str) -> str:\n",
    "    results = vector_store.similarity_search(query=text,k=1)\n",
    "    docs = \"\"\n",
    "    for doc in results:\n",
    "        docs+=f\"{doc.page_content} [{doc.metadata}]\"\n",
    "    return docs\n",
    "\n",
    "rag_tool = Tool(\n",
    "     name=\"Research on Machine Learning Algorithms and Feature Extraction for Time Series\",\n",
    "     func=rag_tool_func,\n",
    "     description=\"Research on Machine Learning Algorithms and Feature Extraction for Time Series\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rag_tool_func(text=\"what is Machine Learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    use_tool: bool = False  # Add this field to control tool usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[nl_to_sql_tool, web_search_tool, calculator_tool, rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State):\n",
    "  return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23f615d29c0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Adding chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Manually create a node for tools without ToolsNode\n",
    "def tools_node(state):\n",
    "    tool_results = []\n",
    "    for tool_call in state[\"messages\"][-1][\"tool_calls\"]:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_input = tool_call[\"parameters\"][\"input\"]\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_name:\n",
    "                tool_results.append(tool.run(tool_input))\n",
    "    return {\"messages\": state[\"messages\"] + tool_results}\n",
    "\n",
    "graph_builder.add_node(\"tools\", tools_node)\n",
    "\n",
    "# Manually define the condition function\n",
    "def tools_condition(state):\n",
    "    if \"tool_calls\" in state[\"messages\"][-1]:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Add conditional edges\n",
    "\n",
    "# Connect edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "try:  \n",
    "    graph_image = graph.get_graph().draw_mermaid_png()  \n",
    "    display(Image(graph_image))  \n",
    "except Exception as e:  \n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are an AI assistant designed to handle various tasks including:\n",
      "- Answering general knowledge questions.\n",
      "- Performing mathematical calculations.\n",
      "- Retrieving real-time information from the web.\n",
      "- Providing research-based answers from the vector database.\n",
      "- Handling natural language queries efficiently.\n",
      "- Use the appropriate tool to generate sql query.\n",
      "\n",
      "Instructions:\n",
      "- Always keep the response concise and clear.\n",
      "- If the user asks for real-time information, prioritize the web search tool.\n",
      "- If the query relates to mathematical expressions, use the calculator tool.\n",
      "- If the user seeks in-depth or document-based information, use the RAG tool.\n",
      "- For everything else, generate a response using the LLM.\n",
      "\n",
      "Be accurate, helpful, and concise.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, I understand the instructions. I will use the appropriate tool or generate a response using the language model based on the user's question, ensuring to keep the response concise and accurate. I will prioritize web search for real-time information, calculator for mathematical expressions, and the RAG tool for in-depth or document-based information. I will not mention any details about using tools or following instructions to the user.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Generate a sql query for users who have placed orders in the last 30 days.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Natural Language to SQL (call_x66k)\n",
      " Call ID: call_x66k\n",
      "  Args:\n",
      "    __arg1: Generate a SQL query to select users who have placed orders in the last 30 days\n"
     ]
    }
   ],
   "source": [
    "# ✅ Start the conversation with the system prompt\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"system\", system_prompt)]}, \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# ✅ Process the system response\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# ✅ Preserve the conversation history\n",
    "state = event  # Capture the last event's state\n",
    "\n",
    "# ✅ First user input\n",
    "user_input = \"Generate a sql query for users who have placed orders in the last 30 days.\"\n",
    "\n",
    "# ✅ Continue the conversation\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": state[\"messages\"] + [(\"user\", user_input)]\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# ✅ Process the response\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# ✅ Update the state again for follow-up questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is time series\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Time series is a sequence of data points measured typically at successive times, spaced at uniform time intervals. It can be used to analyze trends, cycles, and other patterns in data over time. Examples of time series data include stock prices, weather data, and sensor readings.\n",
      "\n",
      "(Note: This response is generated by the language model without using any tools.)\n"
     ]
    }
   ],
   "source": [
    "state = event  # Capture the new state\n",
    "\n",
    "# ✅ Follow-up question\n",
    "follow_up_question = \"what is time series\"\n",
    "\n",
    "# ✅ Continue the conversation with the follow-up question\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": state[\"messages\"] + [(\"user\", follow_up_question)], \n",
    "        \"use_tool\": False\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# ✅ Process the response to the follow-up question\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# ✅ Keep updating the state if you plan to ask more follow-up questions\n",
    "state = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you explain how it's use in machine learning'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, time series data is used in machine learning for various applications such as forecasting, anomaly detection, and pattern recognition. Machine learning algorithms can learn patterns and trends from historical time series data and make predictions for future values. Some popular machine learning techniques used for time series analysis include ARIMA, SARIMA, LSTM (Long Short-Term Memory) networks, and Prophet. These algorithms take into account the temporal dependence and seasonality present in time series data to make accurate predictions. Time series analysis can be used in various fields such as finance, economics, weather forecasting, and IoT (Internet of Things) to make informed decisions and optimize processes.\n",
      "\n",
      "(Note: This response is generated by the language model without using any tools.)\n"
     ]
    }
   ],
   "source": [
    "state = event  # Capture the new state\n",
    "\n",
    "# ✅ Follow-up question\n",
    "follow_up_question = \"Can you explain how it's use in machine learning'\"\n",
    "\n",
    "# ✅ Continue the conversation with the follow-up question\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": state[\"messages\"] + [(\"user\", follow_up_question)]\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# ✅ Process the response to the follow-up question\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# ✅ Keep updating the state if you plan to ask more follow-up questions\n",
    "state = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Generate a sql query for users who have placed orders in the last 30 days\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Natural Language to SQL (call_dfd5)\n",
      " Call ID: call_dfd5\n",
      "  Args:\n",
      "    __arg1: Generate a SQL query to select users who have placed orders in the last 30 days\n"
     ]
    }
   ],
   "source": [
    "state = event  # Capture the new state\n",
    "\n",
    "# ✅ Follow-up question\n",
    "follow_up_question = \"Generate a sql query for users who have placed orders in the last 30 days\"\n",
    "\n",
    "# ✅ Continue the conversation with the follow-up question\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": state[\"messages\"] + [(\"user\", follow_up_question)], \n",
    "        \"use_tool\": False\n",
    "    },\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# ✅ Process the response to the follow-up question\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# ✅ Keep updating the state if you plan to ask more follow-up questions\n",
    "state = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Annotated\n",
    "# from typing_extensions import TypedDict\n",
    "\n",
    "# #Annotated and TypedDict for managing the\n",
    "# #state of the graph\n",
    "\n",
    "# #working with tools\n",
    "\n",
    "# from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "# from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "\n",
    "# #Arxiv and Wikipedia tools\n",
    "\n",
    "# arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=300)\n",
    "# arxiv_tool=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "\n",
    "# api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=300)\n",
    "# wiki_tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "\n",
    "# print(wiki_tool.invoke(\"who is Sharukh Khan\"))\n",
    "# print(arxiv_tool.invoke(\"Attention is all you need\"))\n",
    "# tools=[wiki_tool]\n",
    "\n",
    "# ## Langgraph Application\n",
    "# from langgraph.graph.message import add_messages\n",
    "# class State(TypedDict):\n",
    "#   messages:Annotated[list,add_messages]\n",
    "\n",
    "# from langgraph.graph import StateGraph,START,END\n",
    "# graph_builder= StateGraph(State)\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "# groq_api_key=\"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\"\n",
    "# llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
    "# llm\n",
    "# llm_with_tools=llm.bind_tools(tools=tools)\n",
    "\n",
    "# def chatbot(state:State):\n",
    "#   return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# graph_builder.add_node(\"chatbot\",chatbot)\n",
    "# tool_node = ToolNode(tools=tools)\n",
    "# graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# graph_builder.add_conditional_edges(\n",
    "#     \"chatbot\",\n",
    "#     tools_condition,\n",
    "# )\n",
    "# graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "# graph_builder.add_edge(START,\"chatbot\")\n",
    "\n",
    "# graph=graph_builder.compile()\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception:\n",
    "#     # This requires some extra dependencies and is optional\n",
    "#     pass\n",
    "\n",
    "\n",
    "# user_input=\"Hi there!, My name is John\"\n",
    "\n",
    "# events=graph.stream(\n",
    "#      {\"messages\": [(\"user\", user_input)]},stream_mode=\"values\"\n",
    "# )\n",
    "\n",
    "# for event in events:\n",
    "#   event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# user_input = \"what is RLHF.\"\n",
    "\n",
    "# # The config is the **second positional argument** to stream() or invoke()!\n",
    "# events = graph.stream(\n",
    "#     {\"messages\": [(\"user\", user_input)]},\n",
    "#     stream_mode=\"values\"\n",
    "# )\n",
    "# for event in events:\n",
    "#     event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
